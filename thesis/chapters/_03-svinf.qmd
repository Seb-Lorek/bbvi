---
bibliography: ["bib/references.bib", "bib/packages.bib"]
---

# Stochastic variational inference {#sec-svinf}

<!-- Short introduction on SVI -->

In [Chapter @sec-vinf], we delved into VI and its primary objective, the ELBO, as defined in (@eq-elbo). Furthermore, we introduced CAVI as an inference algorithm to solve the maximization objective in (@eq-elbo-opt). If each full conditional of the parameter blocks is in the exponential family we are able to find optimal factors provided in \eqref{eq-factor-cavi}, ensuring that we maximize the ELBO with each iteration when updating the variational parameters to their expected values from the full conditional distributions. Thus we found closed form solutions to the optimal variational parameters.

In their seminal paper, @Hoffman2012 introduce SVI into CAVI to enhance the scalability of the inference algorithm, enabling it to effectively process large datasets^[But, it remains essential for each full conditional to belong to the exponential family.]. Their approach involves updating the global parameters, in Bayesian models that also contain observation specific latent paratemeters, using stochastic gradient descent (SGD) optimization^[To prevent any potential confusion, it's important to note that while we commonly refer to SGD, within the context of optimizing the ELBO, we actually rely on stochastic gradient ascent. However as most numerical optimization routines are minimizers we usually minimize the negative ELBO in a implementation, which explains the general usage of the term SGD even in the context of maximization.]. @Hoffman2012's algorithm iteratively computes a cheap and noisy gradient of the ELBO to refine the currrent global paramter estimate. The term cheap is aptly used because it relies on a random subset of the complete dataset, and noisy describes the stochasticity of the estimate. Stochastic optimizations algorithms work with noisy yet unbiased approximations of the orginal optimization objective. @Robbins1951 demonstrated that employing a diminishing step size $\rho_{t}$, subject to the conditions outlined in [Appendix @sec-r-m-algo], guarantees the algorithm's ultimate convergence to a global or local optimum depending if the obejective function is convex or non-convex. Since the ELBO represents a non-convex objective we attain a local optimum. Furthermore, noisy gradients are more computationally cost-effective and frequently help in circumventing local optima in complex objective functions [@Hoffman2012, p. 1317]. It is generally the case that in many statistical estimation problems one deals with a sum of terms in the objective function and thus also in the gradient. Consider f.e. the ELBO in the Bayesian linear regression model introduced in @sec-binf, where the ELBO can be written as

\begin{align}
    \text{ELBO}(\phivec) &= \text{E}_{q(\thetavec | \phivec)} \left[ \ln \left( \frac{p(\yvec, \thetavec | \X)}{q(\thetavec | \phivec)} \right) \right] \\
    &= \text{E}_{q(\thetavec | \phivec)} \left[ \ln \left( p(\yvec| \X, \thetavec) p(\thetavec) \right) \right] - \text{E}_{q(\thetavec | \phivec)} \left[ \ln \left( q(\thetavec | \phivec) \right) \right] \\
    &= \text{E}_{q(\thetavec | \phivec)} \left[ \ln \left( \prod_{i=1}^{n} p(y_{i} | \xvec_{i}, \thetavec ) p(\thetavec) \right) \right] - \text{E}_{q(\thetavec | \phivec)} \left[ \ln \left( q(\thetavec | \phivec) \right) \right] \\
    &= \text{E}_{q(\thetavec | \phivec)} \left[ \sum_{i=1}^{n} \ln \left( p(y_{i} | \xvec_{i}, \thetavec) \right)  + \ln \left( p(\thetavec) \right) \right] - \text{E}_{q(\thetavec | \phivec)} \left[ \ln \left( q(\thetavec | \phivec) \right) \right] \\
    &= \sum_{i=1}^{n} \text{E}_{q(\thetavec | \phivec)} \left[ \ln \left( p(y_{i}| \xvec_{i}, \thetavec ) \right) \right] +  \text{E}_{q(\thetavec | \phivec)} \left[ \ln \left( p(\thetavec) \right) \right] - \text{E}_{q(\thetavec | \phivec)} \left[ \ln \left( q(\thetavec | \phivec) \right) \right] \label{eq-elbo-breg}.
\end{align}

The initial component of the ELBO in \eqref{eq-elbo-breg} represents the expected likelihood, which, in turn, entails a summation across all observations. This enables us to efficiently employ a random subset of the dataset, resulting in an unbiased approximation of the ELBO. Let us first introduce a discrete uniform random variable that chooses one index or a set of size M indices of the data.

$$
\mathcal{I}_{m} \sim U(1, \dots, n), \ \mathcal{I}_{m} \in \{1, \dots, n \}, \ \forall m \in \{1, \dots, M\}
$$

When dealing with a set of indices, one can choose between sampling with or without replacement [@Hoffman2012, p. 1320]. This allows us to construct a random function that is a noisy yet unbiased approximation of \eqref{eq-elbo-breg}.

$$
\text{ELBO}(\phivec)_{\mathcal{I}} = \frac{n}{M} \sum_{m = 1}^{M} \text{E}_{q(\thetavec | \phivec)} \left[ \ln \left( p(y_{\mathcal{I}_{m}}| \xvec_{\mathcal{I}_{m}}, \thetavec ) \right) \right] +  \text{E}_{q(\thetavec | \phivec)} \left[ \ln \left( p(\thetavec) \right) \right] - \text{E}_{q(\thetavec | \phivec)} \left[ \ln \left( q(\thetavec | \phivec) \right) \right]
$$ {#eq-elbo-breg-approx}

$\mathcal{I}$ denotes the dependence, of the noisy ELBO, on the set of discrete uniform random variables. In SVI we replace the objective function $\text{ELBO}(\phivec)$, by this random function $\text{ELBO}(\phivec)_{\mathcal{I}}$. The expectation of (@eq-elbo-breg-approx) over the discrete uniform random variable(s) is equal to the ELBO objective in \eqref{eq-elbo-breg}, and thus $\text{E}_{\mathcal{I}} \left[ \text{ELBO}(\phivec)_{\mathcal{I}} \right] = \text{ELBO}(\phivec)$. This enables us to extend the result to the gradients:  $\text{E}_{\mathcal{I}} \left[ \nabla_{\phivec} \text{ELBO}(\phivec)_{\mathcal{I}} \right] = \nabla_{\phivec} \text{ELBO}(\phivec)$. Hence, the gradient of (@eq-elbo-breg-approx) constitutes a noisy yet unbiased estimate of the ELBO's gradient, which can be used in SGD. In essence the algorithm optimizes $\text{ELBO}(\phivec)$ by iteratively using realizations of $\nabla_{\phivec} \text{ELBO}(\phivec)_{\mathcal{I}}$. In each iteration $t$ we update the variational parameters in the following way

$$
\begin{split}
    \hat{\phivec}^{t} = \hat{\phivec}^{t-1} + \rho_{t} \nabla_{\phivec} \text{ELBO}(\phivec)_{\mathcal{I}^{t}} \Bigr\rvert_{\phivec = \hat{\phivec}^{t-1}}.
\end{split}
$$ {#eq-elbo-sgd}

$\mathcal{I}^{t}$ is an independent realization of the random indices and the noisy gradient is evaluated at $\hat{\phivec}^{t-1}$. For a model that comprises only global parameters, the efficiency gain is relatively minor, primarily stemming from the reduction in the summation within the expected likelihood. Nevertheless, this reduction can yield significant improvements in computational efficiency, especially when dealing with very large datasets. In contrast, for models that incorporate local parameters, the efficiency gain is considerably greater, as there's no need to iterate through the entire dataset for each latent parameter, given their observation-specific nature.

The speed of convergence for the SGD optimization algorithm additionally hinges on the variance of the gradient estimator. Therefore, employing a lower variance estimator significantly enhances the convergence speed. Expanding the set of considered observations, also known as the mini-batch size, serves to diminish the variance of the gradient estimator, facilitating the utilization of larger step sizes $\rho_{t}$, as noted by @Zhang2017 [p. 5]. However, this benefit comes at a trade-off, because we increase the computational burden by increasing the mini-batches as outlined above. Thus we could fix either the step size or the mini-batch size and optimally adjust the other quantity. It is a common practice to maintain a fixed mini-batch size while fine-tuning the step size. This approach involves decreasing the step size inversely with the gradient noise. There are many improved variants of SGD, and one well-studied optimizer is Adam, as introduced by @Kingma2014, which dynamically adjusts the step size during optimization. 

Another difficulty in the calculation of the ELBO, that we have sofar not considered, is that the ELBO and, consequently, its gradient necessitate to calculate an expectation over the variational distribution. This implies that when optimizing the ELBO, we must either possess the ability to derive a closed-form solution for this typically high-dimensional integral or resort to numerical integration techniques to approximate it. A commonly used method, particularly when the variational family adheres to the mean-field family and the factors in the variational distribution are normal distributions, is Gaussian-Hermite quadrature [@Steen1969]. While this technique demonstrates good performance for 1-D integrals, its accuracy significantly decreases when handling higher-dimensional integrals. Another numerical integration technique is the trapeziodal rule, which tends to be prohibitively computational expensive. A method that works well especially in high dimensional settings is Monte Carlo integration, already introduced in @sec-binf. Due to that it is common to approximate the integral in the ELBO or its gradient with this method.

\begin{align}
    \text{ELBO}(\phivec) &= \int q(\thetavec | \phivec) \ln \left( \frac{p(\yvec, \thetavec | \X)}{q(\thetavec | \phivec)} \right) \,d \thetavec \label{eq-elbo-int}\\
    \nabla_{\phivec} \text{ELBO}(\phivec) &= \nabla_{\phivec} \int q(\thetavec | \phivec) \ln \left( \frac{p(\yvec, \thetavec | \X)}{q(\thetavec | \phivec)} \right) \,d \thetavec \label{eq-elbo-grad}
\end{align}

Through the utilization of Monte Carlo integration on either \eqref{eq-elbo-int} or \eqref{eq-elbo-grad}, we can effectively compute the integral, with samples from the variational distribution. Applying Monte Carlo integration on the gradient  yields

\begin{align}
    \nabla_{\phivec} \text{ELBO}(\phivec) &= \nabla_{\phivec} \int q(\thetavec | \phivec) \ln \left( \frac{p(\yvec, \thetavec | \X)}{q(\thetavec | \phivec)} \right) \,d \thetavec \\
    &\approx \nabla_{\phivec} \frac{1}{S} \sum_{s=1}^{S} \ln \left( \frac{p(\yvec, \thetavec^{s} | \X)}{q(\thetavec^{s} | \phivec)} \right), \ \thetavec^{s} \sim q(\thetavec | \phivec) \label{eq-mc-elbo-grad}.
\end{align}

The samples $\thetavec^{s}$ are obtained from the variational distribution, illustrating the necessity of efficiently drawing samples from the variational distribution $q(\thetavec | \phivec)$ and evaluating the variational distribution at the samples in \eqref{eq-mc-elbo-grad}. A word of caution is warranted here, while it may appear straightforward to directly apply Monte Carlo integration to \eqref{eq-elbo-grad} and compute the gradient, this approach is not feasible. Because we are not able to pull $\nabla_{\phivec}$ inside of the Monte Carlo integral in \eqref{eq-mc-elbo-grad}. Modifying $\phivec$ even infinitesimal renders the previously generated samples $\thetavec^{s}$ invalid, since they were originally drawn with the parameter $\phivec$ and thus depend on this parameter. This becomes apparent when analyzing the plate notation in @fig-plate-reg^[All plate notations of the probabilistic graphical models use the Tikz [@tikz] library BayesNet [@bayesnet].], where the dependence of the samples on $\phivec$ is obvious. Hence we need to modify the gradient in \eqref{eq-mc-elbo-grad}, to be able to combine Monte Carlo integration and SGD optimization.

```{r, engine='tikz'}
#| label: fig-plate-reg
#| fig-cap: "Plate notation of the dependence structure in a Bayesian regression model for VI, when sampling from the variational distribution."
#| fig-scap: "Plate notation of the model dependence in VI."

\usetikzlibrary{bayesnet}

% Plate diagram
\begin{tikzpicture}
    % Define nodes
    \node[obs] (y) {$y_{i}$};
    \node[const, above=of y] (x) {$\mathbf{x}_{i}$};
    \node[latent, right=of y, xshift=1cm] (t) {$\boldsymbol{\theta}^{s}$};
    \node[const, above=of t] (p) {$\boldsymbol{\phi}$};

    % Connect the nodes
    \edge [shorten <= 2pt] {x,t} {y};
    \edge [shorten <= 2pt] {p} {t};

    % Plates
    \plate {yx} {(y)(x)} {$i = 1, \dots, n$} ;
    \plate {t} {(t)} {$s = 1, \dots, S$} ;

\end{tikzpicture}
```

In the upcoming two subsections, we will introduce two widely employed gradient estimators within the context of SVI. These estimators effectively tackle this challenge, enabling us to seamlessly integrate both the utilization of a random subset of the data and Monte Carlo integration for computing the gradient of the ELBO in SGD.

## Score gradient estimator {#sec-score-grd}

<!-- Derive score gradient estimator -->

The score gradient estimator^[Sometimes also referred to as reinforcement gradient estimator.], as introduced in @Ranganath2014, is a frequently used gradient estimator for computing the gradient of the ELBO. Essentially, we first derive the theoretical gradient of the ELBO w.r.t. $\phivec$ and then employ Monte Carlo integration to approximate the expectation over the variational distribution to evaluate the gradient.

$$
\begin{split}
    \nabla_{\phivec}\text{ELBO}(\phivec) &= \nabla_{\phivec} \int q(\thetavec | \phivec) \ln \left( \frac{p(\yvec, \thetavec | \X)}{q(\thetavec | \phivec)} \right) \,d \thetavec \\
    &= \text{E}_{q(\thetavec | \phivec)} \left[ \nabla_{\phivec} \ln( q(\thetavec | \phivec)) \ln \left( \frac{p(\yvec, \thetavec | \X)}{q(\thetavec | \phivec)} \right) \right]\\
    &\approx \frac{1}{S} \sum_{s=1}^{S} \nabla_{\phivec} \ln( q(\thetavec | \phivec) ) \Bigr\rvert_{\thetavec = \thetavec^{s}} \ln \left( \frac{p(\yvec, \thetavec^{s} | \X)}{q(\thetavec_{s} | \phivec)} \right), \; \thetavec^{s} \sim q(\thetavec | \phivec)
\end{split}
$$

The full derivation is provided in [Appendix @sec-deriv-score-grd]. This gradient estimator circumvents the issue outlined in @sec-svinf, as we only evaluate the gradient $\nabla_{\phivec} \ln( q(\thetavec | \phivec) )$ at the variational sample in the Monte Carlo integration. The cornerstone of the score gradient estimator lies in the derivative of the log variational distribution w.r.t. the variational parameters. Note that the gradient of the logarithm of a probability distribution in statistics is often referred to as the score function. In the context of $\nabla_{\phivec} \ln( q(\thetavec | \phivec) )$, this gives rise to the term "score gradient estimator". For the mean-field variational family, this derivation is generally straightforward. However, for more complex variational families, theoretically deriving this derivative can be quite challenging. Hence it is common to use automatic differentiation to obtain the gradient in such cases. Interestingly, we can readily observe that this gradient solely necessitates the derivative of the logarithm of the variational distribution and samples from the variational distribution. This fundamental aspect explains the usage of this gradient in "black-box" inference algorithms, as it does not rely on model specific derivations or samples. Instead, it merely requires the ability to evaluate the joint log density of the model, whether it's normalized or unnormalized. This flexibility enables the application of the algorithm to arbitrary model definitions, even beyond the scope of conditionally conjugate models. One would build a library (of derivatives) of log probability densities that are commonly employed for parameter blocks in the mean-field family, which can afterwards be used as resuable building blocks during optimization.

Finally, we can integrate this estimator into SVI presented in @Hoffman2012, where we again subsample observations and compute a cheap noisy gradient. Reconsider our familiar Bayesian linear regression model (@sec-binf) for which we obtain the following noisy score gradient estimator

$$
\begin{split}
    \nabla_{\phivec}\text{ELBO}(\phivec)_{\mathcal{I}} &= \frac{1}{S} \sum_{s=1}^{S} \left( \nabla_{\phivec} \ln( q(\thetavec | \phivec) ) \Bigr\rvert_{\thetavec = \thetavec^{s}}  \left[ \frac{n}{M} \sum_{m = 1}^{M} \ln( p(y_{\mathcal{I}_{m}}| \xvec_{\mathcal{I}_{m}}, \thetavec_{s}) ) + \ln( p(\thetavec_{s}) ) \right] \right) \\
    &{\hspace{12pt}} - \frac{1}{S} \sum_{s=1}^{S} \left( \nabla_{\phivec} \ln( q(\thetavec | \phivec) ) \Bigr\rvert_{\thetavec = \thetavec^{s}} \ln ( q(\thetavec_{s} | \phivec) ) \right), \; \thetavec^{s} \sim q(\thetavec | \phivec).
\end{split}
$$

It is common to employ variance reduction techniques to this gradient estimator since the score gradient has a rather high variance. Directly employing this estimator would result in very small steps during SGD optimization, leading to a slow convergence [@Ranganath2014, p. 817]. The most common methods employed are Rao-Blackwellization [@Casella1996] and control variates [@Ross2001; @Paisley2012]. The general idea of these techniques is to replace the gradient estimator with a function that has the same expectation but a smaller variance [@Ranganath2014, p. 817]. Because it holds that

$$
\int q(\thetavec | \phivec) \nabla_{\phivec} \ln( q(\thetavec | \phivec) ) \,d \thetavec = 0,
$$ {#eq-exp-deriv-log-var}

we can add any multiple of this equation to the score gradient estimator. This allows for effective variance reduction techniques. A short explanation of one common control variate is provided in [Appendix @sec-contr-var], but for in depth details consult @Ranganath2014.

The core challenge with the score gradient estimator lies in the fact that we sum over $S$  gradient vectors $\nabla_{\phivec} \ln( q(\thetavec | \phivec) )\Bigr\rvert_{\thetavec = \thetavec^{s}}$ that are randomly oriented and exhibit zero expectation. Moreover, these vectors lack any information about the posterior distribution, leading to a sluggish convergence in high-dimensional parameter spaces. Furthermore, at each iteration $t$ during optimization, it is necessary to obtain a sample of size $S$ from the variational distribution using the current estimates of variational parameters. Demonstrating the significance of effortlessly acquiring samples from the variational distribution. Contrary to the reparameterization gradient estimator, which we will introduce shortly in @sec-rep-grd, the score gradient estimator readily accommodates discrete (categorical) parameters.

## Reparameterization gradient estimator {#sec-rep-grd}

<!-- Derive the reparam. gradient estimator -->

The reparameterization gradient estimator stands today as one of the most frequently used gradient estimation techniques within the realm of SVI [@Kingma2013; @Rezende2014; @Kucukelbir2016]. Its objectives can be succinctly summarized as follows: Firstly, it seeks to seamlessly integrate Monte Carlo integration with SGD. Secondly, it aspires to yield an improved gradient estimator when contrasted with the score gradient estimator in terms of alignment with the posterior distribution and variance during optimization. The reparameterization gradient estimator achieves this by explicitly including information of the posterior. Lastly, it enables the utilization of contemporary technologies such as automatic differentiation directly on the ELBO.

In a first step we need to remove the direct dependence between the samples of  $\thetavec^{s}$ and $\phivec$, to be able to differentiate w.r.t. $\phivec$ inside of the Monte Carlo integral in \eqref{eq-mc-elbo-grad}. This can be achieved by reparameterizing $\boldsymbol{\theta}$. For the time being, we will exclusively focus on continuous parameters, omitting discrete parameters from our current discussion. The change of variable theorem for probability density functions (transformation law, vector to vector) allows us to apply a bijective, differentiable function $\gvec_{\phivec}()$, which depends on a parameter vector $\phivec$, to a continous random variable $\epsilonvec$ such that $\thetavec$ is a transformation of $\epsilonvec$ with the following properties

$$
\begin{split}
    \gvec_{\phivec} : \mathbb{R}^{d} &\to \mathbb{R}^{d}; \ \thetavec, \epsilonvec \in \mathbb{R}^{d} \\
    \thetavec &= \gvec_{\phivec}(\epsilonvec), \; \epsilonvec \sim \mathcal{N}(\zerovec, \I)\\
    q(\thetavec | \phivec) &= \begin{cases}
                    p_{\epsilonvec}(\gvec^{-1}_{\phivec}(\thetavec)) \left|\det(\J_{\gvec^{-1}_{\phivec}})\right|, & \text{if $\thetavec$ is in the codomain of $\gvec_{\phivec}$}\\
                    0, & \text{else.}
                    \end{cases}
\end{split}
$$

$\J_{\gvec^{-1}_{\phivec}} \in \mathbb{R}^{d \times d}$ is the Jacobian^[The determinant of the Jacobian corrects for the volume compression due to the variable transformation, such that the transformed density still integrates to one [@Kucukelbir2016, p. 6].] with

$$
\begin{split}
    \J_{\gvec^{-1}_{\phivec}} = \begin{bmatrix}
                                    \nabla^{\mathrm{T}}_{\thetavec} \gvec^{-1}_{\phivec}(\thetavec)_{1} \\
                                    \vdots \\
                                    \nabla^{\mathrm{T}}_{\thetavec} \gvec^{-1}_{\phivec}(\thetavec)_{d} \\
                                \end{bmatrix},
    \ \text{with}
    \ \nabla^{\mathrm{T}}_{\thetavec} &= \left( \frac{\partial}{\partial\theta_{1}}, \ \dots, \frac{\partial}{\partial\theta_{d}} \right).
\end{split}
$$

The function $\gvec_{\phivec}$ can take on either linear or nonlinear forms, and we will delve into common choices in @sec-bbvi. In the specification above, we assume that the noise distribution of $\epsilonvec$, which governs the stochasticity of $\thetavec$, follows a standard multivariate normal distribution. However, it can take on any distributional form for which we can readily obtain samples and evaluate the density. Essentially the variational distribution is now a deterministic parametric transformation of a noise distribution, such that $q(\thetavec | \phivec)$ and $\gvec_{\phivec}$ depend on the variational parmater vector $\phivec$ [@Zhang2017, p. 8]. Importantly the noise distribution is completely independent of the of the parameters in $\phivec$. The reparameterization of $\thetavec$ essentially allows us to move the samples of $\thetavec^{s}$ with changes in $\phivec$. A revised dependency structure for a Bayesian regression model, incorporating the "reparameterization trick"^[This is the terminology @Kingma2013 use to discribe their technique.], is depicted in @fig-plate-reg-repara.

```{r, engine='tikz'}
#| label: fig-plate-reg-repara
#| fig-cap: "Plate notation of the dependence structure in a Bayesian regression model in VI, using the \"reparameterization-trick\"."
#| fig-scap: "Plate notation of the model dependence in VI, using reparameterization."

\usetikzlibrary{bayesnet}

% Plate diagram
\begin{tikzpicture}
    % Define nodes
    \node[obs] (y) {$y_{i}$};
    \node[const, above=of y] (x) {$\mathbf{x}_{i}$};
    \node[latent, right=of y] (t) {$\boldsymbol{\theta}^{s}$};
    \node[const, above=of t] (p) {$\boldsymbol{\phi}$};
    \node[latent, right=of t, xshift=1cm] (e) {$\boldsymbol{\epsilon}^{s}$};
    \node[const, above=of e, xshift=-1cm] (mu) {$\boldsymbol{\mu}_{\boldsymbol{\epsilon}}$};
    \node[const, above=of e, xshift=1cm] (sig) {$\boldsymbol{\Sigma}_{\boldsymbol{\epsilon}}$};

    % Connect the nodes
    \edge [shorten <= 2pt] {x,t} {y};
    \edge [shorten <= 2pt] {mu,sig} {e};
    \edge [shorten <= 2pt] {p} {t};
    \edge [shorten <= 2pt] {e} {t};

    % Plates
    \plate {yx} {(y)(x)} {$i = 1, \dots, n$} ;
    \plate {e} {(e)} {$s = 1, \dots, S$} ;

\end{tikzpicture}
```

It is important to notice that we only sample $\epsilonvec$ and after that apply the function $\gvec_{\phivec}$ to obtain the samples for $\thetavec$, being defined as $\thetavec = \gvec_{\phivec}(\epsilonvec)$. Thus we use the superscript $\thetavec^{s}$ in @fig-plate-reg-repara to denote it's dependence on the samples $\epsilonvec^{s}$. Therefore we can calculate the expectation over $\thetavec$ in the ELBO as an expectation over $\epsilonvec$, on which $\thetavec$ depends deterministically, using the change of variables for multiple variables (integration by substitution). Such that we can express the ELBO as 

$$
\begin{split}
    \text{ELBO}(\phivec) &= \text{E}_{q(\thetavec | \phivec)} \left[ \ln \left( \frac{p(\yvec, \thetavec | \X)}{q(\thetavec | \phivec)} \right) \right] \\
    &= \text{E}_{p(\epsilonvec)} \left[ \ln \left( \frac{p(\yvec, \thetavec = \gvec_{\phivec}(\epsilonvec) | \X)}{q(\thetavec = \gvec_{\phivec}(\epsilonvec) | \phivec)} \right) \right] \\
    &= \int p(\epsilonvec) \ln \left( \frac{p(\yvec, \thetavec = \gvec_{\phivec}(\epsilonvec) | \X)}{q(\thetavec = \gvec_{\phivec}(\epsilonvec) | \phivec)} \right) \;d \epsilonvec.
\end{split}
$$

Using this expression, we can rewrite the gradient of the ELBO as 

\begin{align}
    \nabla_{\phivec} \text{ELBO}(\phivec) &= \nabla_{\phivec} \int p(\epsilonvec) \ln \left( \frac{p(\yvec, \thetavec = \gvec_{\phivec}(\epsilonvec) | \X)}{q(\thetavec = \gvec_{\phivec}(\epsilonvec) | \phivec)} \right) \;d \epsilonvec \\
    &= \int p(\epsilonvec) \nabla_{\phivec} \ln \left( \frac{p(\yvec, \thetavec = \gvec_{\phivec}(\epsilonvec) | \X)}{q(\thetavec = \gvec_{\phivec}(\epsilonvec) | \phivec)} \right) \;d \epsilonvec  \label{eq-repara-grad-1}\\
    &= \int p(\epsilonvec) \nabla_{\thetavec} \ln \left( \frac{p(\yvec, \thetavec = \gvec_{\phivec}(\epsilonvec) | \X)}{q(\thetavec = \gvec_{\phivec}(\epsilonvec) | \phivec)} \right) \nabla_{\phivec} \gvec_{\phivec}(\epsilonvec) \;d \epsilonvec \label{eq-repara-grad-2}.
\end{align}

Where we applied the chain rule from \eqref{eq-repara-grad-1} to \eqref{eq-repara-grad-2}. Finally we can approximate the intgeral using Monte Carlo integration in the following way
$$
\begin{split}
    \nabla_{\phivec} \text{ELBO}(\phivec) &\approx \frac{1}{S} \sum_{s=1}^{S} \nabla_{\thetavec} \ln \left( \frac{p(\yvec, \thetavec = \gvec_{\phivec}(\epsilonvec)| \X)}{q(\thetavec = \gvec_{\phivec}(\epsilonvec) | \phivec)} \right) \Bigr\rvert_{\thetavec = \thetavec^{s}} \nabla_{\phivec} \gvec_{\phivec}(\epsilonvec^{s}), \\
    \text{with} \; \thetavec_{\phivec}^{s} &= \gvec_{\phivec}(\epsilonvec^{s}), \; \epsilonvec^{s} \sim \mathcal{N}(\zerovec, \I), \ s = 1, \dots, S.
\end{split}
$$ {#eq-repara-grad-mc}

The new gradient estimator provides better updates to the variational parameters during optimization due to its direct incorporation of posterior information through the term $\nabla_{\thetavec} \ln(p(\yvec, \thetavec = \gvec_{\phivec}(\epsilonvec)| \X))$. Therefore resulting a in a lower variance gradient estimator [@Zhang2017, p. 8]. Although the variance of the reparameterization gradient estimator is generally lower than that of the score gradient estimator, the incorporation of the Monte Carlo integral introduces additional noise, which can be mitigated by also employing control variates [@Zhang2017, p. 9]. Incorporating the term $\nabla_{\thetavec} \ln(p(\yvec, \thetavec = \gvec_{\phivec}(\epsilonvec)| \X))$ of course requires the model to be differentiable, a requirement that is in genereal not overly restrictive [@Kucukelbir2016, p. 4]. Similarly to the score gradient estimator, we are once again able to employ a mini-batch for evaluating the reparameterization gradient estimator in the context of SGD.

Although we theoretically require the gradients $\nabla_{\thetavec} \ln(p(\yvec, \thetavec = \gvec_{\phivec}(\epsilonvec)| \X))$ and $\nabla_{\phivec} \gvec_{\phivec}(\epsilonvec)$, the "reparameterization-trick" illustrated in @fig-plate-reg-repara and the resultant reparameterization gradient estimator in (@eq-repara-grad-mc) demonstrate that we can now use backpropagation by the chain rule. This facilitates automatic differentiation on the ELBO, thereby making it also accessible for use in "black-box" inference algorithms. As a result, there is no need for any model-specific derivations. Once we have defined the model with its joint distribution, we proceed to determine the variational family by establishing the variational distribution using the change of variable theorem for probability density functions. The variational distribution is in turn solely defined by both the noise distribution of $\epsilonvec$ and the transformation function $\gvec_{\phivec}$. After that we are ready to optimize the ELBO with SGD. This also allows to easily implement a library of common transformation functions, for blocks of parameters in the mean-field family, in a software package, such that we can effortlessly fit a wide array of probabilistic models with these building blocks.

Reparameterizing $\thetavec$ through the transformation theorem is effective for continuous parameters, however, it can pose greater challenges when incorporating discrete parameters. In such instances, identifying a suitable transformation function $\gvec_{\phivec}$ becomes more complex, and even when potential candidates arise, they frequently lack differentiability [@Zhang2017, p. 9].

As a side note, while it may not be of paramount importance for this thesis, the reparameterization technique also serves as a cornerstone for amortized VI. Computationally, deriving each latent parameter that pertains to a specific observation can be quite expensive, particularly when the model additionally incorporates global parameters. Therefore, by reparameterizing the latent parameters as $\zvec = \fvec_{\varphivec}(\xvec, y)$, we can substantially mitigate computational costs. This implies that local parameters remain observation-specific through their dependence on $\xvec$, but the inference on the function is global, as it is shared across all observations [@Zhang2017, pp. 13]. The function $\fvec_{\varphivec}$ can potentially be highly non-linear. Armortized VI today finds common application in variational autoencoders (VAEs) [@Kingma2013; @Rezende2014].

## "Black-box" variational inference {#sec-bbvi}

<!-- Introduce BBVI, in the context of the reparamterization gradient estimator -->

Because the class of models with conditionally conjugate distributions in the exponential family is rather limited, a significant amount of research has been directed towards developing VI algorithms that are applicable to non-conjugate models as well. BBVI algorithms are rather recent approaches to generalize VI algorithms to a broad class of models, even non-conjugate models, by avoiding any model-specific derivation [@Blei2017]. We have previously explored SVI and observed that both the score gradient estimator and the reparameterization gradient estimator, as discussed in @sec-score-grd and @sec-rep-grd, enable BBVI within SVI. In the realm of SVI algorithms, it was @Kingma2013, @Rezende2014 and @Ranganath2014 who pioneered the development of derivation-free approaches. The BBVI algorithm studied in this thesis utilizes the reparameterization gradient estimator, due to the improved mathematical properties and the convenience of leveraging modern technology like automatic differentiation directly on the ELBO. Henceforth, we will exclusively focus on this gradient estimator. @Kucukelbir2016 call their implementation automatic differentiation variational inference (ADVI) instead of BBVI but we will still refer to BBVI in this case, as at its heart it also a "black-box" inference algorithm.

Thanks to the "reparameterization-trick", we were able to employ the chain rule in computing the gradient of the ELBO, thereby enabling backpropagation for automatic differentiation. Consequently, employing the reparameterization gradient estimator in SGD as described in (@eq-elbo-sgd), adheres to the idea of @Kucukelbir2016 that the researcher only formulates a probabilistic model and provides a dataset set. The inference algorithm is completely model-agnostic, allowing the reasearcher to explore different model formulations at ease. The "reparameterization trick", as outlined in @sec-rep-grd, can be extended to each block of parameters denoted as $\thetavec_{j}$. Consequently, this establishes a mean-field variational family across parameter blocks, where we currently employ the same function $\gvec$ across different parameter blocks, but with different parameterizations. It's again important to note that we can only employ the same function $\gvec$ if all the parameter blocks within $\thetavec$ are continuous parameters. This specification results in the familiar mean-field variational family with the following distribution

$$
q(\thetavec | \phivec) = \prod_{j = 1}^{J} q(\thetavec_{j} | \phivec_{j}).
$$

While this seems to be a resaonable approach we neglected that each block might adhere to a different parameter space $\Thetabold_{j} \subseteq \mathbb{R}^{d_{j}}$. Hence, before we are able to employ a common transformation function we need to transform all parameter spaces to a common space, where we usually opt for the real space $\mathbb{R}^{D}$ with dimension $D = \sum_{j=1}^{J}d_{j}$. By taking this step, we circumvent constrained optimization, thereby simplifying the optimization task. Thus for parameters that have a restricted parameter space we need to add another layer of transformation where we transform the restricted space to the real space. For scale parameters that have a positive parameter space, we usually use the log transformation. In general, we can employ a different transformation function, denoted as $\svec$, which ideally does not involve any parameters. This establishes the following relationship

$$
\begin{split}
    \thetavec_{j} &= \svec(\tilde{\thetavec}_{j}) \\
    \tilde{\thetavec}_{j} &= \svec^{-1}(\thetavec_{j}).
\end{split}
$$

$\svec$ transforms the parameter back to the appropriate parameter space, while $\svec^{-1}$ maps the parameter to the unconstrained real space. This allows the application of a common transformation function $\gvec$ for all the factors in the variational distribution, independetly of the original parameter space. Essentially this is another layer where we apply the change of variable theorem for probability density functions. The function $\svec$ then implies the following factor for $\thetavec_{j}$

$$
\begin{split}
    q( \thetavec_{j} | \phivec_{j}) = \begin{cases}
                    q_{\tilde{\thetavec}_{j}}(\svec^{-1}(\thetavec) | \phivec) \left|\det(\J_{\svec^{-1}})\right|, & \text{if $\thetavec$ is in the codomain of $\svec$}\\
                    0, & \text{else.}
                    \end{cases}
\end{split}
$$

Bear in mind that $q_{\tilde{\thetavec}_{j}}$ was already the application of the the change of variable theorem using the function $\gvec_{\phivec_{j}}$. Implementation wise we can build functions that sepecify the choosen transformation function $\svec$ such that we automatically transform the support of the parameter block $\thetavec_{j}$ to the real space. Hence we don't need to worry about any support matching constraints [@Kucukelbir2016, p. 5]. @Kucukelbir2016 also study the sensitivity of the variational distribution for different transformation functions $\svec$ in the case of a positive parameters. The authors find that the function $\svec(\cdot) = \ln(\exp(\cdot) +1)$ leads to better approximations of the posterior in terms of KL diveregence compare to just using a log transformation $\svec(\cdot) = \exp(\cdot)$. They restrict their finding however to the case where the posterior is a light-tailed distribution [@Kucukelbir2016, p. 15].

<!-- Introduce bbvi with a linear transformation function -->

As previously mentioned, the transformation function $\gvec_{\phivec_{j}}$ entirely governs the factor within the variational distribution parameterized with the variational parameter vector $\phivec_{j}$ in the unconstrained space. This function can exhibit linearity or non-linearity. A frequently selected linear choice is to employ

$$
\begin{split}
    \epsilonvec_{j} &\sim \mathcal{N}(\zerovec, \I) \\
    \tilde{\thetavec}_{j} &= \gvec_{\phivec_{j}}(\epsilonvec_{j}) \\
    &= \Lbold_{j} \epsilonvec_{j} + \muvec_{j}.
\end{split}
$$

The parameter vector of the function is thus the collection of $\phivec_{j} = ( \muvec_{j}^{\mathrm{T}}, \vect(\Lbold_{j})^{\mathrm{T}} )^{\mathrm{T}}$. It can be easily shown that with such a parameterization $\tilde{\thetavec}_{j}$ follows a multivariate normal distribution with the following specification

$$
\begin{split}
    \tilde{\thetavec}_{j} &\sim \mathcal{N}(\muvec_{j}, \Sigmabold_{j}), \ \text{with} \\
    \Sigmabold_{j} &= \Lbold_{j} \Lbold_{j}^{\mathrm{T}}.
\end{split}
$$

With this linear transformation $\gvec_{\phivec_{j}}$ we are transforming one multivariate normal distribution to another by the change of variable theorem [@Kucukelbir2016, p. 8]. Here from a multivariate standard normal distribution to a multivarate normal distribution with mean and covariance matrix defined above. $\Lbold_{j}$ is usually chosen to be a lower triangular matrix, such that it represent the lower triangular matrix from a Cholesky decompostition. This ensures that during optimization, we have no constraints on the lower triangular elements in the matrix and the resulting covariance matrix $\Sigmabold_{j}$ remains positive-definite. This corresponds to the non-unique definition of the Cholesky factorization, allowing the diagonal elements of $\mathbf{L}_j$ to lack positivity constraints [@Kucukelbir2016]. To derive the unique definition of Cholesky factorization, it is necessary to impose constraints on the positivity of the diagonal elements within the lower triangular matrix. This constraint can be easily satisfied by optimizing the diagonal elements in the logarithmic space and subsequently converting them back using the exponential function. In total we have $d_{j}$ variational parameters for the mean and $\frac{d_{j}(d_{j}+1)}{2}$ variational parameters for the covariance matrix of a parameter in the model. This implies that the number of variational parameters we have to optimize for grows quadratic with the dimension of the parameter. Hence for regressions models that include smooth effects one obtains a siceable amount of variational paramters, since a smooth effect usually implies a high dimensional parameter space. Please note that in cases involving constrained parameters, while a multivariate normal distribution is utilized in the unconstrained real space of the parameter blocks, the resulting distribution for constrained parameters does not conform to a multivariate normal distribution, instead it follows a log-multivariate normal distribution.

Incorporating discrete parameters presents a greater challenge, necessitating the utilization of a distinct transformation function and noise distribution, compared to continuous parameters. For an approach to model discrete parameters consult @Jang2016. To achieve a more flexible variational distribution, advanced techniques encompass the use of non-linear transformation functions by using cutting-edge machine learning approaches such as normalizing flows [@Rezende2015]. The only requirements for $\gvec_{\phivec_{j}}$ are that it must be a bijective and differentiable function. Efficiency considerations furthermore dictate that we should be able to rapidly evaluate the factor within the variational distribution. This implies that we need the ability to calculate the determinant of the Jacobian matrix with ease. With the specification of the transformation functions $\gvec$ and $\svec$ we have finally fully determined the variational distribution and thus a complete recipe for a BBVI algorithm.

<!-- Example with the Bayesian linear regression model -->

We will now consider a BBVI setup for the Bayesian linear regression to make the theory more tangible. The variational distribution is again

$$
q(\thetavec | \phivec) = q_{\betavec}(\betavec | \phivec_{\betavec} ) q_{\sigma}(\sigma | \phivec_{\sigma}).
$$

With the linear transformation function established above we approximate the posteriors of $\betavec$ and $\ln(\sigma)$, in the unconstrained parameter space, with the following distributions

$$
\begin{split}
    \betavec &\sim \mathcal{N}(\muvec_{\betavec}, \Sigmabold_{\betavec}) \\
    \ln(\sigma) &\sim \mathcal{N}(\mu_{\sigma}, \varsigma_{\sigma}^{2}).
\end{split}
$$

Implying that we used the log-transformation as the function $s^{-1}$ for $\sigma$. The variational parameters in this model are defined as $\phivec = \left( \phivec_{\betavec}^{\mathrm{T}}, \phivec_{\sigma}^{\mathrm{T}} \right)^{\mathrm{T}}$ with $\phivec_{\betavec} = \left(\muvec_{\betavec}^{\mathrm{T}}, \vect( \Lbold_{\betavec} )^{\mathrm{T}} \right)^{\mathrm{T}}$ and $\phivec_{\sigma} = \left( \mu_{\sigma}, \varsigma_{\sigma} \right)^{\mathrm{T}}$. Hence the maximization problem can be specified as

$$
\hat{\phivec} = \argmax_{\phivec} \text{E}_{p(\epsilonvec_{\betavec})p(\epsilon_{\sigma})} \left[ \ln \left( \frac{p(\yvec|\betavec, \sigma, \X) p(\betavec) p(\sigma)}{q_{\betavec}(\betavec = \gvec_{\phivec_{\betavec}}(\epsilonvec_{\betavec})| \phivec_{\betavec} ) q_{\sigma}(\sigma = s(g_{\phivec_{\sigma}}(\epsilon_{\sigma}))| \phivec_{\sigma})} \right) \right].
$$

Notice how the expectation in the ELBO^[We redefine the ELBO in terms of the variational distribtion, in which we account for the volume compression due to the transformation with $\det(\J_{\gvec^{-1}_{\phivec_{j}}})$ and $\det(\J_{\svec^{-1}})$ . @Kucukelbir2016 leave the variational distribution in the unconstrained space and adjust the joint distribution of the model with $\det(\J_{\gvec_{\phivec_{j}}})$ and $\det(\J_{\svec})$.] is now formulated over the noise distrbutions and not over the variational distribution as in (@eq-elbo-opt). Finally we can derive the noisy reparameterization gradient $\nabla_{\phivec}\text{ELBO}(\phivec)_{\mathcal{I}}$ by utilizing a random subset of the data, employing Monte Carlo integration and using automatic differentiation on this ELBO. This automatically derived gradient is subsequently employed in Equation (@eq-elbo-sgd) to iteratively refine the parameter estimates, ultimately guiding the optimization process towards a local optimum of the ELBO. All this is possible without any support matching constrains imposed by the parameter spaces and minimal effort by the researcher.

## The inference algorithm {#sec-inf-alg}

We now have all the components necessary to define our full BBVI algorithm (Algorithm \ref{algo}). In contrast to the theory outlined in @sec-bbvi, where the variational parameters for a parameter block are defined as $\phivec_{j} = ( \muvec_{j}^{\mathrm{T}}, \vect(\Lbold_{j})^{\mathrm{T}} )^{\mathrm{T}}$ with $\Lbold_{j}$ being the lower triangular matrix from a Cholesky decomposition of the covariance matrix, we modify $\Lbold_{j}$ to be the lower triangular matrix of the precision matrix. This is done due to considerations of linear algebra stability. Optimizing the variational distribution in terms of the lower triangular matrix $\Lbold_{j}$ of the precision matrix is typically more numerically stable than optimizing with respect to $\Lbold_{j}$ of the covariance matrix. Furthermore we use the unique definition of the Cholesky decomposition for the precision and hence optimize all diagonal elements of $\Lbold_{j}$ in the unconstrained space (log transformation) and ensure their positivity by using the exponential transformation.

In a first step of the BBVI algorithm we initialize the variational paremeters either with "arbitrary" values or with model specific initializations. A common choice for the "arbitrary" intialization is to set the location parameter of a factor to $\muvec_{j} = \zerovec$. The diagonal elements of $\Lbold_{j}$ are usually set to $\diag(\Lbold_{j}) = \onevec$, resulting in the vector $\zerovec$ in the unconstrained space. A well known model specific initialization for location-scale regression is to set the location parameter $\muvec_{j}$ to the estimates obtained by a penalized least squares (PLS) estimation. However obtaining sensible initializations for the diagonal elements of $\Lbold_{j}$ is more difficult and sensible strategies are yet to be explored.

Subsequently, we divide our data into training $\mathcal{D}_{\text{train}}$ and validation $\mathcal{D}_{\text{val}}$ datasets to mitigate the risk of overfitting. Consequently, we monitor the convergence of the ELBO on the validation dataset. Typically, an 80%/20% split (resulting in a training share $w=0.8$) is employed for the training and validation sets, respectively. In preparation, we also randomly permute the data in advance to eliminate any potential dependencies arising from the initial data structure^[This is possible because we are only dealing with independent data structures here.]. After that we start the optimization by initializing the optimizer with a learning rate $\alpha$ (usually a small number f.e. 1e-2 or 1e-3) and dynamically adjust the step size during the optimization. Adam uses first and second order momentum to dynamically adjust the step size [@Kingma2014]. 

We then run the alogrithm for a pre determined number of epochs $E$. Because we use a mini-batch $\mathcal{I}^{k}$ to calculate the gradient (see [Chapter @sec-svinf]) in each iteration $k$, it is common to refer to an epoch $e$ as one iteration loop of the optimization algorithm such that the algorithm has iterated through the entire training dataset. Fixing the mini-batch size $M$ in advance means that one epoch consist of a fixed number of iterations, given by the number of observations in the training set $n_{\text{train}}$ evenly divided by the mini-batch size $M$. Hence, in each iteration during an epoch, we utilize one mini-batch from the created set of mini-batches $\mathcal{B}$, progressing to the next until we have iterated through all mini-batches. At the start of each epoch, we furthermore permute the training data to ensure variation in the mini-batches across epochs. To avoid losing observations, we augment the mini-batch count by including an additional mini-batch, if necessary, comprising any remaining observations. This mini-batch is augmented with resampled indices from the other training data, conducted without replacement. During each iteration in an epoch, we also obtain samples from the noise distribution, with the sample size $S$ pre-determined in advance. These samples are then transformed to samples from the variational distribution to assess the integral within the ELBO through Monte Carlo integration (see @eq-repara-grad-mc). 

Throughout the optimization process, we iteratively refine the configuration of variational parameters towards the local optimum. Additionally, we compute the value of the ELBO using the validation set, to monitor the convergence. The optimization runs until we either reach the pre-defined maximum number of epochs or we stop by triggering some early-stopping criterion. Stopping through the early-stopping criterion indicates that we reached some form of plateau in the ELBO of the validation data. We use $|\text{ELBO}(\hat{\phivec}^{t})_{\mathcal{D}_{\text{val}}} - \text{ELBO}(\hat{\phivec}^{t-200})_{\mathcal{D}_{\text{val}}}| < \varepsilon$ as the early stopping criteron, $\varepsilon$ being some arbitrary small number. The full BBVI algorithm is roughly outlined in Algorithm \ref{algo}.

\begin{algorithm}[H]
    \DontPrintSemicolon
    \scriptsize
    \SetKwInOut{Require}{Require}
    \KwData{$\mathcal{D}_{\text{train}}$; $\mathcal{D}_{\text{val}}$}
    \Require{Learning rate $\alpha$; stopping threshold $\varepsilon$; mini-batch size $M$; share train $w$; num. var. samples $S$; num. epochs: $E$}
    Initialize $\hat{\phivec}^{0}$; set $t = 1$ \;
    \For{$e = 1$  \KwTo $E$}{
        $n_{\text{train}} = |\mathcal{D}_{\text{train}}| * w$ \;
        create the mini-batches, $\mathcal{B} = \{ \dots, \mathcal{I}^{k}, \dots \}, \ k=1, \dots, n_{\text{train}} // M \ (+1)$ \;
        \For{$k=1$ \KwTo $n_{\text{train}} // M \ (+1)$}{
        sample noise, $\epsilonvec^{s}_{j} \sim \mathcal{N}(\zerovec, \I), \ s=1,\dots, S, \ \forall j$ \;
        calculate approx. gradient, $\nabla_{\phivec} \text{ELBO}(\phivec)_{\mathcal{I}^{k}} \Bigr\rvert_{\phivec = \hat{\phivec}^{t-1}}$\;
        update variational parameters, $\hat{\phivec}^{t} = \hat{\phivec}^{t-1} + \rho_{t} \nabla_{\phivec} \text{ELBO}(\phivec)_{\mathcal{I}^{k}} \Bigr\rvert_{\phivec = \hat{\phivec}^{t-1}}$ \;
        calculate approx. ELBO, $\text{ELBO}(\hat{\phivec}^{t})_{\mathcal{D}_{\text{val}}}$ \;
        $t = t + 1$ \;
        }
        \eIf{$t > 200$}{
            $\Delta \text{ELBO} = |\text{ELBO}(\hat{\phivec}^{t})_{\mathcal{D}_{\text{val}}} - \text{ELBO}(\hat{\phivec}^{t-200})_{\mathcal{D}_{\text{val}}}|$
        }{$\Delta \text{ELBO} = \infty$
        }
        \If{$\Delta \text{ELBO} < \varepsilon$}{
            \textbf{break}\;
        }
    }
    \KwResult{$\hat{\phivec}$; $\text{ELBO}(\hat{\phivec})_{\mathcal{D}_{\text{val}}}$}
    \caption{BBVI algorithm.}
    \label{algo}
\end{algorithm}

Furthermore, we maintain a record of the maximum ELBO attained, denoted as $\text{ELBO}(\hat{\phivec})_{\mathcal{D}_{\text{val}}}$, along with its corresponding optimal parameter configuration $\hat{\phivec}$. These estimates represent the solution derived for the optimization problem.

## ELBO convergence {#sec-elbo-conv}

Throughout the process of SGD optimization, we track the convergence of the ELBO.
Exemplary ELBO traces, illustrating the impact of varying optimization parameters on a Bayesian linear regression model (see @sec-binf), are visualized in @fig-elbo-trace1 through @fig-elbo-trace4. For this small simulation study we generated $n_{\text{obs}}=1000$ data points from the following model $y_{i} | x_{i} \sim \mathcal{N}(1.0 + 2.0x_{i}, 1.0)$, where $x_{i} \sim \mathcal{U}(0,1)$. Because the ELBO constitutes a non-convex objective, optimization converges towards a local optimum which is contingent upon its initialization. Moreover as we work with Monte Carlo integration and mini-batches we additionally introduce stochasticity into the optimization.

@fig-elbo-trace1 shows that we usually start with some low value of the ELBO, dependent on the initialization. After that we can observe a steep increase, in which we improve the ELBO fast due to taking large steps in the optimization. This fast convergence tapers off before epoch 50 for all traces. It is visible that a more effective initialization leads to a faster convergence. In the following, we are only taking smaller optimization steps because we are already close to the local optimum. The figure underscores that the optimal outcome is reliant on the initialization, as depicted in the embedded figure, even when the differences are relatively minor. Please note that we fixed the seed for all runs to control for the dependence of the optimization on stochasticity. 

@fig-elbo-trace2 shows three different optimization runs with the same initial variational parameter configuration, but using distinct seeds. For each run we observe a distinct ELBO trace, eventhough we used the same initialization. However, despite the stochasticity, all traces exhibit a rather similar pattern. It's interesting to note that by employing a distinct seed, the runs converge towards distinctly different local optima. Emphasizing again the impact of the stochasticity on the optimum.

::: {layout="[[50,-5,50], [50,-5,50]]"}

![ELBO traces for 3 different SGD runs, using different initializations but the same seed. We use a batch size of 128, 64 samples from the variational distribution and a learning rate of 1e-2.](assets/plots/plot2.pdf){fig-scap="ELBO traces for different init. and seeds." #fig-elbo-trace1}

![ELBO traces for 3 different SGD runs, using different seeds but the same initialization. Otherwise same configuration as in @fig-elbo-trace1.](assets/plots/plot3.pdf){fig-scap="ELBO traces for different seeds." #fig-elbo-trace2}

![ELBO traces for 3 different SGD runs, using different variational sample sizes. We use batch VI with a learning rate of 1e-2 and the same seed as in @fig-elbo-trace1.](assets/plots/plot4.pdf){fig-scap="ELBO traces for different variational sample sizes." #fig-elbo-trace3}

![ELBO traces for 3 different SGD runs, using different batch sizes. We use a variational sample size of 64 with a learning rate of 1e-2 and the same seed as in @fig-elbo-trace1.](assets/plots/plot5.pdf){fig-scap="ELBO traces for different batch sizes." #fig-elbo-trace4}

:::

The choice of the variational sample size has a significant impact on the convergence of the ELBO. Using a larger variational sample size significantly reduces the variance of the ELBO and thus its gradient (@fig-elbo-trace3). Furthermore, a stable ELBO plateau is quicker achieved when utilizing larger samples drawn from the variational distribution. This lower variance would allows us in general to use a larger learning rate, which consequently results in a faster convergence of the ELBO. Again we use the same seed and all traces converge to a similar local optima. Notably, we can observe that due to the large stochasticity, we are able to attain a higher optimum by using just one sample from the variational distribution. There is a subtle detail to note here: because of the pseudo-random number generation in `JAX`, ensuring identical pseudo-random number generation for pseudo-random `jax.numpy.ndarrays` becomes challenging due to the dependency on the shape of the array. This implies that we can ensure identical pseudo-random number generation solely when utilizing arrays that possess precisely matching shapes, which is not the case here as we change the variational sample size. Consequently, we cannot completely eliminate the stochastic nature from the results, which could potentially elucidate the findings observed in this case (likewise for @fig-elbo-trace4).

Employing a larger batch size results in a reduction of variance, as illustrated in @fig-elbo-trace4 of the ELBO traces. However the reduction is rather minor. Be mindful that the variations in batch size result in different iteration counts per epoch for each run. Therefore, we've adapted @fig-elbo-trace4 by showcasing iterations on the x-axis in this context. Using a larger batch size in this scenario does not result in a superior local optima of the optimization, all ELBO traces vary around a common level.

For predictive purposes one can also monitor the log posterior predictive density. In a first step we would also divide the data set into a training and a validation set. The validation set is then used to asses the average log posterior predictive density. Hence we average over all individual log predictive densities in the validation sample. For some examples in this regard we refer to @Blei2017 and @Kucukelbir2016.