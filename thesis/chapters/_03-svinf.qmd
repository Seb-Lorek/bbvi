---
bibliography: ["bib/references.bib", "bib/packages.bib"]
---

# Stochastic variational inference {#sec-svinf}

<!-- Short introduction on SVI -->

In [Chapter @sec-vinf], we delved into VI and its primary objective, the ELBO, as defined in (@eq-elbo). Furthermore, we introduced CAVI as an inference algorithm to solve the maximization objective in (@eq-elbo-opt). If each full conditional of the parameter blocks is in the exponential family, we are able to find optimal factors provided in \eqref{eq-factor-cavi}, ensuring that we maximize the ELBO with each iteration when updating the variational parameters to their expected values from the full conditional distributions. Thus, we find closed form solutions to the optimal variational parameters.

In their seminal paper, @Hoffman2012 introduce SVI into CAVI to enhance the scalability of the inference algorithm, enabling it to effectively process large datasets^[However, it remains essential for each full conditional to belong to the exponential family.]. Their approach involves updating the global parameters in Bayesian models that also contain observation specific latent paratemeters using stochastic gradient descent (SGD) optimization^[To prevent any potential confusion, it is important to note that while we commonly refer to SGD within the context of optimizing the ELBO, we actually rely on stochastic gradient ascent. However, as most numerical optimization routines are minimizers, we usually minimize the negative ELBO in an implementation, which explains the general usage of the term SGD even in the context of maximization.]. @Hoffman2012's algorithm iteratively computes a "cheap" and "noisy" gradient of the ELBO to refine the currrent global paramter estimate. The term "cheap" is aptly used because it relies on a random subset of the complete dataset, and "noisy" describes the stochasticity of the estimate. Stochastic optimizations algorithms work with noisy yet unbiased approximations of the orginal optimization objective. @Robbins1951 demonstrated that employing a diminishing step size $\rho_{t}$, subject to the conditions outlined in [Appendix @sec-r-m-algo], guarantees the ultimate convergence of the algorithm to a global or local optimum if the obejective function is convex or non-convex. Since the ELBO represents a non-convex objective, we attain a local optimum. Furthermore, noisy gradients are more computationally cost-effective and frequently help in circumventing local optima in complex objective functions [@Hoffman2012, p. 1317]. In many statistical estimation problems, one deals with a sum of terms in the objective function and thus also in the gradient. Consider, e.g., the ELBO in the Bayesian linear regression model introduced in @sec-binf, where the ELBO can be written as

\begin{align}
    \text{ELBO}(\phivec) &= \text{E}_{q(\thetavec | \phivec)} \left[ \ln \left( \frac{p(\yvec, \thetavec | \X)}{q(\thetavec | \phivec)} \right) \right] \\
    &= \text{E}_{q(\thetavec | \phivec)} \left[ \ln \left( p(\yvec| \X, \thetavec) p(\thetavec) \right) \right] - \text{E}_{q(\thetavec | \phivec)} \left[ \ln \left( q(\thetavec | \phivec) \right) \right] \\
    &= \text{E}_{q(\thetavec | \phivec)} \left[ \ln \left( \prod_{i=1}^{n} p(y_{i} | \xvec_{i}, \thetavec ) p(\thetavec) \right) \right] - \text{E}_{q(\thetavec | \phivec)} \left[ \ln \left( q(\thetavec | \phivec) \right) \right] \\
    &= \text{E}_{q(\thetavec | \phivec)} \left[ \sum_{i=1}^{n} \ln \left( p(y_{i} | \xvec_{i}, \thetavec) \right)  + \ln \left( p(\thetavec) \right) \right] - \text{E}_{q(\thetavec | \phivec)} \left[ \ln \left( q(\thetavec | \phivec) \right) \right] \\
    &= \sum_{i=1}^{n} \text{E}_{q(\thetavec | \phivec)} \left[ \ln \left( p(y_{i}| \xvec_{i}, \thetavec ) \right) \right] +  \text{E}_{q(\thetavec | \phivec)} \left[ \ln \left( p(\thetavec) \right) \right] - \text{E}_{q(\thetavec | \phivec)} \left[ \ln \left( q(\thetavec | \phivec) \right) \right] \label{eq-elbo-breg}.
\end{align}

The initial component of the ELBO in \eqref{eq-elbo-breg} represents the expected log-likelihood, which, in turn, entails a summation across all observations. This enables us to efficiently employ a random subset of the dataset, resulting in an unbiased approximation of the ELBO. Let us first introduce a discrete uniform random variable that chooses one index or a set of size M indices of the data

$$
\mathcal{I}_{m} \sim U(1, \dots, n), \ \mathcal{I}_{m} \in \{1, \dots, n \}, \ \forall m \in \{1, \dots, M\}.
$$

When dealing with a set of indices, one can choose between sampling with or without replacement [@Hoffman2012, p. 1320]. This allows us to construct a random function that is a noisy yet unbiased approximation of \eqref{eq-elbo-breg}, when using $\mathcal{I}_{m}$

$$
\begin{split}
\text{ELBO}(\phivec)_{\mathcal{I}} &= \frac{n}{M} \sum_{m = 1}^{M} \text{E}_{q(\thetavec | \phivec)} \left[ \ln \left( p(y_{\mathcal{I}_{m}}| \xvec_{\mathcal{I}_{m}}, \thetavec ) \right) \right] +  \text{E}_{q(\thetavec | \phivec)} \left[ \ln \left( p(\thetavec) \right) \right] \\
    &{\hspace{12pt}} - \text{E}_{q(\thetavec | \phivec)} \left[ \ln \left( q(\thetavec | \phivec) \right) \right].
\end{split}
$$ {#eq-elbo-breg-approx}

$\mathcal{I}$ denotes the dependence of the noisy ELBO on the set of discrete uniform random variable(s). In SVI, we replace the objective function $\text{ELBO}(\phivec)$ by this random function $\text{ELBO}(\phivec)_{\mathcal{I}}$. The expectation of (@eq-elbo-breg-approx) over the discrete uniform random variable(s) is equal to the ELBO objective in \eqref{eq-elbo-breg}, and thus $\text{E}_{\mathcal{I}} \left[ \text{ELBO}(\phivec)_{\mathcal{I}} \right] = \text{ELBO}(\phivec)$. This enables us to extend the result to the gradients:  $\text{E}_{\mathcal{I}} \left[ \nabla_{\phivec} \text{ELBO}(\phivec)_{\mathcal{I}} \right] = \nabla_{\phivec} \text{ELBO}(\phivec)$. Hence, the gradient of (@eq-elbo-breg-approx) constitutes a "noisy" yet unbiased estimate of the gradient of the ELBO, which can be used in SGD. In essence, the algorithm optimizes $\text{ELBO}(\phivec)$ by iteratively using realizations of $\nabla_{\phivec} \text{ELBO}(\phivec)_{\mathcal{I}}$. In each iteration $t$, we update the variational parameters in the following way

$$
\begin{split}
    \hat{\phivec}^{t} = \hat{\phivec}^{t-1} + \rhovec_{t} \odot \nabla_{\phivec} \text{ELBO}(\phivec)_{\mathcal{I}^{t}} \Bigr\rvert_{\phivec = \hat{\phivec}^{t-1}}.
\end{split}
$$ {#eq-elbo-sgd}

$\mathcal{I}^{t}$ is an independent realization of the random indices and the noisy gradient is evaluated at $\hat{\phivec}^{t-1}$. In this notation we also made explicit that we usually have a vector of step sizes $\rhovec_{t}$, namely one step size for each coefficient. For a model that comprises only global parameters, the efficiency gain is relatively minor. Nevertheless, this reduction in data size can yield significant improvements in computational efficiency, especially when dealing with very large datasets. In contrast, for models that incorporate local parameters, the efficiency gain is considerably greater, as there is no need to iterate through the entire dataset for each latent parameter, given their observation-specific nature.

The speed of convergence for the SGD optimization algorithm additionally hinges on the variance of the gradient estimator. Therefore, employing a lower variance estimator significantly enhances the convergence speed. Expanding the set of considered observations, also known as the mini-batch size, serves to diminish the variance of the gradient estimator, facilitating the utilization of larger step sizes $\rho_{t}$, as noted by @Zhang2017 [p. 5]. However, this benefit comes at a trade-off, because we increase the computational burden by increasing the mini-batches as outlined above. Thus, we can either fix the step size or the mini-batch size and optimally adjust the other quantity. It is common practice to maintain a fixed mini-batch size while fine-tuning the step size. This approach involves decreasing the step size inversely with the gradient noise. There are a lot of improved variants of SGD. One well-studied optimizer is Adam, as introduced by @Kingma2014, which dynamically adjusts the step size during optimization. 

Another difficulty in the calculation of the ELBO, which we have sofar not considered until now, is that the ELBO and, consequently, its gradient necessitate the calculation of an expectation over the variational distribution. This implies that when optimizing the ELBO, we must either possess the ability to derive a closed-form solution for this typically high-dimensional integral or resort to numerical integration techniques to approximate it. A commonly used method, particularly when the variational family adheres to the mean-field family and the factors in the variational distribution are normal distributions, is Gaussian-Hermite quadrature [@Steen1969]. While this technique demonstrates good performance for 1-D integrals, its accuracy significantly decreases when handling higher-dimensional integrals. Another numerical integration technique is the trapeziodal rule, which tends to be prohibitively computational expensive. A method that works well especially in high dimensional settings is Monte Carlo integration, already introduced in @sec-binf. Thus, it is common to approximate the integral in the ELBO or its gradient with this method

\begin{align}
    \text{ELBO}(\phivec) &= \int q(\thetavec | \phivec) \ln \left( \frac{p(\yvec, \thetavec | \X)}{q(\thetavec | \phivec)} \right) \,d \thetavec \label{eq-elbo-int}\\
    \nabla_{\phivec} \text{ELBO}(\phivec) &= \nabla_{\phivec} \int q(\thetavec | \phivec) \ln \left( \frac{p(\yvec, \thetavec | \X)}{q(\thetavec | \phivec)} \right) \,d \thetavec \label{eq-elbo-grad}.
\end{align}

Through the utilization of Monte Carlo integration for either \eqref{eq-elbo-int} or \eqref{eq-elbo-grad}, we can effectively compute the integral with samples from the variational distribution. Applying Monte Carlo integration on the gradient  yields

\begin{align}
    \nabla_{\phivec} \text{ELBO}(\phivec) &= \nabla_{\phivec} \int q(\thetavec | \phivec) \ln \left( \frac{p(\yvec, \thetavec | \X)}{q(\thetavec | \phivec)} \right) \,d \thetavec \\
    &\approx \nabla_{\phivec} \frac{1}{S} \sum_{s=1}^{S} \ln \left( \frac{p(\yvec, \thetavec^{s} | \X)}{q(\thetavec^{s} | \phivec)} \right), \ \thetavec^{s} \sim q(\thetavec | \phivec) \label{eq-mc-elbo-grad}.
\end{align}

The samples $\thetavec^{s}$ are obtained from the variational distribution, illustrating the necessity of efficiently drawing samples from the variational distribution $q(\thetavec | \phivec)$ and evaluating the variational distribution at the samples in \eqref{eq-mc-elbo-grad}. A word of caution is warranted here: While it may appear straightforward to directly apply Monte Carlo integration to \eqref{eq-elbo-grad} and compute the gradient, this approach is not feasible, because we are not able to pull $\nabla_{\phivec}$ inside of the Monte Carlo integral in \eqref{eq-mc-elbo-grad}. Modifying $\phivec$ even infinitesimally renders the previously generated samples $\thetavec^{s}$ invalid, since they were originally drawn with the parameter $\phivec$ and thus depend on this parameter. This becomes apparent when analyzing the plate notation^[All plate notations of the probabilistic graphical models use the Tikz [@tikz] library BayesNet [@bayesnet].] in @fig-plate-reg, where the dependence of the samples on $\phivec$ is obvious. Hence, we need to modify the gradient in \eqref{eq-mc-elbo-grad} to be able to combine Monte Carlo integration and SGD optimization.

```{r, engine='tikz'}
#| label: fig-plate-reg
#| fig-cap: "Plate notation of the dependence structure in a Bayesian regression model for VI when sampling from the variational distribution."
#| fig-scap: "Plate notation of the model dependence in VI."

\usetikzlibrary{bayesnet}

% Plate diagram
\begin{tikzpicture}
    % Define nodes
    \node[obs] (y) {$y_{i}$};
    \node[const, above=of y] (x) {$\mathbf{x}_{i}$};
    \node[latent, right=of y, xshift=1cm] (t) {$\boldsymbol{\theta}^{s}$};
    \node[const, above=of t] (p) {$\boldsymbol{\phi}$};

    % Connect the nodes
    \edge [shorten <= 2pt] {x,t} {y};
    \edge [shorten <= 2pt] {p} {t};

    % Plates
    \plate {yx} {(y)(x)} {$i = 1, \dots, n$} ;
    \plate {t} {(t)} {$s = 1, \dots, S$} ;

\end{tikzpicture}
```

In the upcoming two subsections, we will introduce two widely employed gradient estimators within the context of SVI. These estimators effectively tackle this challenge, enabling us to seamlessly integrate both the utilization of a random subset of the data and Monte Carlo integration for computing the gradient of the ELBO in SGD.

## Score gradient estimator {#sec-score-grd}

<!-- Derive score gradient estimator -->

The score gradient estimator^[Sometimes also referred to as reinforcement gradient estimator.], as introduced in @Ranganath2014, is a frequently used gradient estimator for computing the gradient of the ELBO. Essentially, we first derive the theoretical gradient of the ELBO w.r.t. $\phivec$ and then employ Monte Carlo integration to approximate the expectation over the variational distribution to evaluate the gradient

$$
\begin{split}
    \nabla_{\phivec}\text{ELBO}(\phivec) &= \nabla_{\phivec} \int q(\thetavec | \phivec) \ln \left( \frac{p(\yvec, \thetavec | \X)}{q(\thetavec | \phivec)} \right) \,d \thetavec \\
    &= \text{E}_{q(\thetavec | \phivec)} \left[ \nabla_{\phivec} \ln( q(\thetavec | \phivec)) \ln \left( \frac{p(\yvec, \thetavec | \X)}{q(\thetavec | \phivec)} \right) \right]\\
    &\approx \frac{1}{S} \sum_{s=1}^{S} \nabla_{\phivec} \ln( q(\thetavec | \phivec) ) \Bigr\rvert_{\thetavec = \thetavec^{s}} \ln \left( \frac{p(\yvec, \thetavec^{s} | \X)}{q(\thetavec_{s} | \phivec)} \right), \; \thetavec^{s} \sim q(\thetavec | \phivec).
\end{split}
$$

The full derivation is provided in [Appendix @sec-deriv-score-grd]. This gradient estimator circumvents the issue outlined in the introduction to @sec-svinf, as we only evaluate the gradient $\nabla_{\phivec} \ln( q(\thetavec | \phivec) )$ at the variational sample in the Monte Carlo integration. The cornerstone of the score gradient estimator lies in the derivative of the log variational distribution w.r.t. the variational parameters. The logarithm of a probability distribution in statistics is commonly known as the score function. In the context of $\nabla_{\phivec} \ln( q(\thetavec | \phivec) )$, this gives rise to the term "score gradient estimator". For the mean-field variational family, this derivation is generally straightforward. However, for more complex variational families, deriving this derivative theoretically can be quite challenging. Hence, it is common to use automatic differentiation to obtain the gradient in such cases. Interestingly, we can readily observe that the gradient solely necessitates the derivative of the logarithm of the variational distribution and samples from the variational distribution. This fundamental aspect explains the usage of this gradient in "black box" inference algorithms, as it does not rely on model specific derivations or samples. Instead, it merely requires the ability to evaluate the joint log-density of the model, whether it is normalized or unnormalized. This flexibility enables the application of the algorithm to arbitrary model definitions, even beyond the scope of conditionally conjugate models. To this end, one would build a library of log-probability densities that are commonly employed for parameter blocks in the mean-field family (or their derivatives), which can afterwards be used as resuable building blocks during optimization.

Finally, we can integrate this estimator into SVI as presented in @Hoffman2012, where we again subsample observations and compute a cheap noisy gradient. Reconsider our familiar Bayesian linear regression model (@sec-binf), for which we obtain the following noisy score gradient estimator

$$
\begin{split}
    \nabla_{\phivec}\text{ELBO}(\phivec)_{\mathcal{I}} &= \frac{1}{S} \sum_{s=1}^{S} \left( \nabla_{\phivec} \ln( q(\thetavec | \phivec) ) \Bigr\rvert_{\thetavec = \thetavec^{s}}  \left[ \frac{n}{M} \sum_{m = 1}^{M} \ln( p(y_{\mathcal{I}_{m}}| \xvec_{\mathcal{I}_{m}}, \thetavec_{s}) ) + \ln( p(\thetavec_{s}) ) \right] \right) \\
    &{\hspace{12pt}} - \frac{1}{S} \sum_{s=1}^{S} \left( \nabla_{\phivec} \ln( q(\thetavec | \phivec) ) \Bigr\rvert_{\thetavec = \thetavec^{s}} \ln ( q(\thetavec_{s} | \phivec) ) \right), \; \thetavec^{s} \sim q(\thetavec | \phivec).
\end{split}
$$

It is common to employ variance reduction techniques to this gradient estimator since the score gradient has a rather high variance. Directly employing this estimator would result in very small steps during SGD optimization, leading to a slow convergence [@Ranganath2014, p. 817]. The most common methods employed are Rao-Blackwellization [@Casella1996] and control variates [@Ross2001; @Paisley2012]. The general idea of these techniques is to replace the gradient estimator with a function that has the same expectation but a smaller variance [@Ranganath2014, p. 817]. Since it holds that

$$
\int q(\thetavec | \phivec) \nabla_{\phivec} \ln( q(\thetavec | \phivec) ) \,d \thetavec = 0,
$$ {#eq-exp-deriv-log-var}

we can add any multiple of this equation to the score gradient estimator. This allows for effective variance reduction techniques. A short explanation of one common control variate is provided in [Appendix @sec-contr-var]. For in depth details consult @Ranganath2014.

The core challenge of the score gradient estimator lies in the fact that we sum over $S$  gradient vectors $\nabla_{\phivec} \ln( q(\thetavec | \phivec) )\Bigr\rvert_{\thetavec = \thetavec^{s}}$, which are randomly oriented and exhibit zero expectation. Moreover, these vectors lack any information about the posterior distribution, leading to a sluggish convergence in high-dimensional parameter spaces. Furthermore, at each iteration $t$ during optimization, it is necessary to obtain a sample of size $S$ from the variational distribution using the current estimates of variational parameters, demonstrating the significance of effortlessly acquiring samples from the variational distribution. Contrary to the reparameterization gradient estimator, which we will introduce shortly in @sec-rep-grd, the score gradient estimator readily accommodates discrete (categorical) parameters.

## Reparameterization gradient estimator {#sec-rep-grd}

<!-- Derive the reparam. gradient estimator -->

The reparameterization gradient estimator stands today as one of the most frequently used gradient estimation techniques within the realm of SVI [@Kingma2013; @Rezende2014; @Kucukelbir2016]. Its objectives can be succinctly summarized as follows: Firstly, it seeks to seamlessly integrate Monte Carlo integration with SGD. Secondly, it aspires to yield an improved gradient estimator when contrasted with the score gradient estimator in terms of alignment with the posterior distribution and variance during optimization. The reparameterization gradient estimator achieves this by explicitly including information of the posterior. Lastly, it enables the utilization of contemporary technologies such as automatic differentiation directly on the ELBO.

In a first step, we need to remove the direct dependence between the samples of  $\thetavec^{s}$ and $\phivec$ to be able to differentiate w.r.t. $\phivec$ inside of the Monte Carlo integral in \eqref{eq-mc-elbo-grad}. This can be achieved by reparameterizing $\boldsymbol{\theta}$. For the time being, we will exclusively focus on continuous parameters, omitting discrete parameters from our current discussion. The change of variable theorem for probability density functions (vector to vector) allows us to apply a bijective, differentiable function $\gvec_{\phivec}()$, which depends on a parameter vector $\phivec$, to a continous random variable $\epsilonvec$ such that $\thetavec$ is a transformation of $\epsilonvec$ with the following properties

$$
\begin{split}
    \gvec_{\phivec} : \mathbb{R}^{d} &\to \mathbb{R}^{d}; \ \thetavec, \epsilonvec \in \mathbb{R}^{d} \\
    \thetavec &= \gvec_{\phivec}(\epsilonvec), \; \epsilonvec \sim \mathcal{N}(\zerovec, \I)\\
    q(\thetavec | \phivec) &= \begin{cases}
                    p_{\epsilonvec}(\gvec^{-1}_{\phivec}(\thetavec)) \left|\det(\J_{\gvec^{-1}_{\phivec}})\right|, & \text{if $\thetavec$ is in the codomain of $\gvec_{\phivec}$}\\
                    0, & \text{else.}
                    \end{cases}
\end{split}
$$

$\J_{\gvec^{-1}_{\phivec}} \in \mathbb{R}^{d \times d}$ is the Jacobian^[The determinant of the Jacobian corrects for the volume compression due to the variable transformation such that the transformed density still integrates to one [@Kucukelbir2016, p. 6].] with

$$
\begin{split}
    \J_{\gvec^{-1}_{\phivec}} = \begin{bmatrix}
                                    \nabla^{\mathrm{T}}_{\thetavec} \gvec^{-1}_{\phivec}(\thetavec)_{1} \\
                                    \vdots \\
                                    \nabla^{\mathrm{T}}_{\thetavec} \gvec^{-1}_{\phivec}(\thetavec)_{d} \\
                                \end{bmatrix},
    \ \text{with}
    \ \nabla^{\mathrm{T}}_{\thetavec} &= \left( \frac{\partial}{\partial\theta_{1}}, \ \dots, \frac{\partial}{\partial\theta_{d}} \right).
\end{split}
$$

The function $\gvec_{\phivec}$ can take either linear or nonlinear forms and we will delve into common choices in @sec-bbvi. In the specification above, we assume that the noise distribution of $\epsilonvec$, which governs the stochasticity of $\thetavec$, follows a standard multivariate normal distribution. However, it can take any distributional form for which we can readily obtain samples and evaluate the density. Essentially the variational distribution is now a deterministic parametric transformation of a noise distribution such that $q(\thetavec | \phivec)$ and $\gvec_{\phivec}$ depend on the variational parmater vector $\phivec$ [@Zhang2017, p. 8]. Importantly, the noise distribution is completely independent of the of the parameters in $\phivec$. The reparameterization of $\thetavec$ essentially allows us to move the samples of $\thetavec^{s}$ with changes in $\phivec$. A revised dependence structure for a Bayesian regression model, incorporating the "reparameterization trick"^[This is the terminology @Kingma2013 use to discribe their technique.], is depicted in @fig-plate-reg-repara.

```{r, engine='tikz'}
#| label: fig-plate-reg-repara
#| fig-cap: "Plate notation of the dependence structure in a Bayesian regression model in VI using the \"reparameterization trick\"."
#| fig-scap: "Plate notation of the model dependence in VI, using reparameterization."

\usetikzlibrary{bayesnet}

% Plate diagram
\begin{tikzpicture}
    % Define nodes
    \node[obs] (y) {$y_{i}$};
    \node[const, above=of y] (x) {$\mathbf{x}_{i}$};
    \node[latent, right=of y] (t) {$\boldsymbol{\theta}^{s}$};
    \node[const, above=of t] (p) {$\boldsymbol{\phi}$};
    \node[latent, right=of t, xshift=1cm] (e) {$\boldsymbol{\epsilon}^{s}$};
    \node[const, above=of e, xshift=-1cm] (mu) {$\boldsymbol{\mu}_{\boldsymbol{\epsilon}}$};
    \node[const, above=of e, xshift=1cm] (sig) {$\boldsymbol{\Sigma}_{\boldsymbol{\epsilon}}$};

    % Connect the nodes
    \edge [shorten <= 2pt] {x,t} {y};
    \edge [shorten <= 2pt] {mu,sig} {e};
    \edge [shorten <= 2pt] {p} {t};
    \edge [shorten <= 2pt] {e} {t};

    % Plates
    \plate {yx} {(y)(x)} {$i = 1, \dots, n$} ;
    \plate {e} {(e)} {$s = 1, \dots, S$} ;

\end{tikzpicture}
```

It is important to notice that we only sample $\epsilonvec$ and after that apply the function $\gvec_{\phivec}$ to obtain the samples for $\thetavec$, which are defined as $\thetavec = \gvec_{\phivec}(\epsilonvec)$. Thus, we use the superscript $\thetavec^{s}$ in @fig-plate-reg-repara to denote it's dependence on the samples $\epsilonvec^{s}$. Therefore, we can calculate the expectation over $\thetavec$ in the ELBO as an expectation over $\epsilonvec$, on which $\thetavec$ depends deterministically, using the change of variables for multiple variables (integration by substitution), such that we can express the ELBO as 

$$
\begin{split}
    \text{ELBO}(\phivec) &= \text{E}_{q(\thetavec | \phivec)} \left[ \ln \left( \frac{p(\yvec, \thetavec | \X)}{q(\thetavec | \phivec)} \right) \right] \\
    &= \text{E}_{p(\epsilonvec)} \left[ \ln \left( \frac{p(\yvec, \thetavec = \gvec_{\phivec}(\epsilonvec) | \X)}{q(\thetavec = \gvec_{\phivec}(\epsilonvec) | \phivec)} \right) \right] \\
    &= \int p(\epsilonvec) \ln \left( \frac{p(\yvec, \thetavec = \gvec_{\phivec}(\epsilonvec) | \X)}{q(\thetavec = \gvec_{\phivec}(\epsilonvec) | \phivec)} \right) \;d \epsilonvec.
\end{split}
$$

Using this expression, we can rewrite the gradient of the ELBO as 

\begin{align}
    \nabla_{\phivec} \text{ELBO}(\phivec) &= \nabla_{\phivec} \int p(\epsilonvec) \ln \left( \frac{p(\yvec, \thetavec = \gvec_{\phivec}(\epsilonvec) | \X)}{q(\thetavec = \gvec_{\phivec}(\epsilonvec) | \phivec)} \right) \;d \epsilonvec \\
    &= \int p(\epsilonvec) \nabla_{\phivec} \ln \left( \frac{p(\yvec, \thetavec = \gvec_{\phivec}(\epsilonvec) | \X)}{q(\thetavec = \gvec_{\phivec}(\epsilonvec) | \phivec)} \right) \;d \epsilonvec  \label{eq-repara-grad-1}\\
    &= \int p(\epsilonvec) \nabla_{\thetavec} \ln \left( \frac{p(\yvec, \thetavec = \gvec_{\phivec}(\epsilonvec) | \X)}{q(\thetavec = \gvec_{\phivec}(\epsilonvec) | \phivec)} \right) \nabla_{\phivec} \gvec_{\phivec}(\epsilonvec) \;d \epsilonvec \label{eq-repara-grad-2},
\end{align}

where we apply the chain rule from \eqref{eq-repara-grad-1} to \eqref{eq-repara-grad-2}. Finally, we can approximate the intgeral using Monte Carlo integration in the following way
$$
\begin{split}
    \nabla_{\phivec} \text{ELBO}(\phivec) &\approx \frac{1}{S} \sum_{s=1}^{S} \nabla_{\thetavec} \ln \left( \frac{p(\yvec, \thetavec = \gvec_{\phivec}(\epsilonvec)| \X)}{q(\thetavec = \gvec_{\phivec}(\epsilonvec) | \phivec)} \right) \Bigr\rvert_{\thetavec = \thetavec^{s}} \nabla_{\phivec} \gvec_{\phivec}(\epsilonvec^{s}), \\
    \text{with} \; \thetavec_{\phivec}^{s} &= \gvec_{\phivec}(\epsilonvec^{s}), \; \epsilonvec^{s} \sim \mathcal{N}(\zerovec, \I), \ s = 1, \dots, S.
\end{split}
$$ {#eq-repara-grad-mc}

The new gradient estimator provides better updates to the variational parameters during optimization due to its direct incorporation of posterior information through the term $\nabla_{\thetavec} \ln(p(\yvec, \thetavec = \gvec_{\phivec}(\epsilonvec)| \X))$, therefore resulting in a lower variance gradient estimator [@Zhang2017, p. 8]. Although the variance of the reparameterization gradient estimator is generally lower than that of the score gradient estimator, the incorporation of the Monte Carlo integral introduces additional noise, which can be mitigated by employing control variates [@Zhang2017, p. 9]. Incorporating the term $\nabla_{\thetavec} \ln(p(\yvec, \thetavec = \gvec_{\phivec}(\epsilonvec)| \X))$ requires the model to be differentiable, a requirement that is in genereal not overly restrictive [@Kucukelbir2016, p. 4]. Similarly to the score gradient estimator, we are once again able to employ a mini-batch for evaluating the reparameterization gradient estimator in the context of SGD.

Although we theoretically require the gradients $\nabla_{\thetavec} \ln(p(\yvec, \thetavec = \gvec_{\phivec}(\epsilonvec)| \X))$ and $\nabla_{\phivec} \gvec_{\phivec}(\epsilonvec)$, the "reparameterization trick" illustrated in @fig-plate-reg-repara and the resulting reparameterization gradient estimator in (@eq-repara-grad-mc) demonstrate that we can now use backpropagation by the chain rule. This facilitates automatic differentiation on the ELBO, thereby making it accessible for use in "black box" inference algorithms. As a result, there is no need for any model-specific derivations. Once we have defined the model with its joint distribution, we proceed to determine the variational family by establishing the variational distribution using the change of variable theorem for probability density functions. The variational distribution is in turn solely defined by the noise distribution of $\epsilonvec$ and the transformation function $\gvec_{\phivec}$. Afterwards, we are ready to optimize the ELBO with SGD. This also allows to easily implement a library of common transformation functions for blocks of parameters in the mean-field family in a software package such that we can effortlessly fit a wide array of probabilistic models with these building blocks.

Reparameterizing $\thetavec$ through the transformation theorem is effective for continuous parameters, however, it can pose challenges when incorporating discrete parameters. In such instances, identifying a suitable transformation function $\gvec_{\phivec}$ becomes more complex, and even if potential candidates arise, they frequently lack differentiability [@Zhang2017, p. 9].

## "Black box" variational inference {#sec-bbvi}

<!-- Introduce BBVI, in the context of the reparamterization gradient estimator -->

Since the class of models with conditionally conjugate distributions in the exponential family is rather limited, a significant amount of research has been directed towards developing VI algorithms that are applicable to non-conjugate models as well. BBVI algorithms are rather recent approaches to generalize VI algorithms to a broad class of models, even non-conjugate models, by avoiding any model-specific derivations [@Blei2017]. We have previously explored SVI and observed that both the score gradient estimator and the reparameterization gradient estimator, as discussed in @sec-score-grd and @sec-rep-grd, enable BBVI within SVI. In the realm of SVI algorithms, it was @Kingma2013, @Rezende2014, and @Ranganath2014 who pioneered the development of derivation-free approaches. The BBVI algorithm studied in this thesis utilizes the reparameterization gradient estimator due to its improved mathematical properties and the convenience of leveraging modern technology like automatic differentiation directly on the ELBO. Henceforth, we will exclusively focus on this gradient estimator. @Kucukelbir2016 call their implementation "automatic differentiation variational inference" (ADVI) instead of BBVI, but we will still refer to BBVI in this case, as it is also a "black box" inference algorithm at its heart.

Thanks to the "reparameterization trick", we are able to employ the chain rule in computing the gradient of the ELBO, thereby enabling backpropagation for automatic differentiation. Consequently, employing the reparameterization gradient estimator in SGD as described in (@eq-elbo-sgd) adheres to the idea of @Kucukelbir2016 that the researcher only formulates a probabilistic model and provides a dataset set. The inference algorithm is completely model-agnostic, allowing the reasearcher to explore different model formulations at ease. The "reparameterization trick", as outlined in @sec-rep-grd, can be extended to each block of parameters denoted as $\thetavec_{j}$. This establishes a mean-field variational family across parameter blocks, where we currently employ the same function $\gvec$ across different parameter blocks but with different parameterizations. It is important to note that we can only employ the same function $\gvec$ if all the parameter blocks within $\thetavec$ have the same parameter space. This specification results in the mean-field variational family with the following distribution

$$
q(\thetavec | \phivec) = \prod_{j = 1}^{J} q_{j}(\thetavec_{j} | \phivec_{j}).
$$

While this seems to be a resaonable approach, we neglect that each block might adhere to a different parameter space $\Thetabold_{j} \subseteq \mathbb{R}^{d_{j}}$. Hence, before we are able to employ a common transformation function, we need to transform all parameter spaces to a common space, where we usually opt for the real space $\mathbb{R}^{D}$ with dimension $D = \sum_{j=1}^{J}d_{j}$. By taking this step, we circumvent constrained optimization, thereby simplifying the optimization task. Thus, for parameters that have a restricted parameter space, we need to add another layer of transformation, where we transform the restricted space to the real space. For scale parameters that have a positive parameter space, we usually use the log-transformation. In general, we can employ a different transformation function, denoted as $\svec$, which ideally does not involve any parameters. This establishes the following relationship

$$
\begin{split}
    \thetavec_{j} &= \svec(\tilde{\thetavec}_{j}) \\
    \tilde{\thetavec}_{j} &= \svec^{-1}(\thetavec_{j}).
\end{split}
$$

$\svec$ transforms the parameter back to the appropriate parameter space, while $\svec^{-1}$ maps the parameter to the unconstrained real space. This allows the application of a common transformation function $\gvec$ for all the factors in the variational distribution independent of the original parameter space. Essentially, this is another layer where we apply the change of variable theorem for probability density functions. The function $\svec$ then implies the following factor for $\thetavec_{j}$

$$
\begin{split}
    q_{j}( \thetavec_{j} | \phivec_{j}) = \begin{cases}
                    q_{\tilde{\thetavec}_{j}}(\svec^{-1}(\thetavec) | \phivec) \left|\det(\J_{\svec^{-1}})\right|, & \text{if $\thetavec$ is in the codomain of $\svec$}\\
                    0, & \text{else.}
                    \end{cases}
\end{split}
$$

Bear in mind that $q_{\tilde{\thetavec}_{j}}$ was already the application of the the change of variable theorem using the function $\gvec_{\phivec_{j}}$. Implementation wise, we can build functions that sepecify the choosen transformation function $\svec$ such that we automatically transform the support of the parameter block $\thetavec_{j}$ to the real space. Hence, we do not need to worry about any support matching constraints [@Kucukelbir2016, p. 5]. 

<!-- Introduce bbvi with a linear transformation function -->

As previously mentioned, the transformation function $\gvec_{\phivec_{j}}$ entirely governs the factor within the variational distribution parameterized with the variational parameter vector $\phivec_{j}$ in the unconstrained space. This function can exhibit linearity or non-linearity. A frequently selected linear choice is to employ

$$
\begin{split}
    \epsilonvec_{j} &\sim \mathcal{N}(\zerovec, \I) \\
    \tilde{\thetavec}_{j} &= \gvec_{\phivec_{j}}(\epsilonvec_{j}) \\
    &= \Lbold_{j} \epsilonvec_{j} + \muvec_{j}.
\end{split}
$$

The parameter vector of the function is thus the collection of $\phivec_{j} = ( \muvec_{j}^{\mathrm{T}}, \vect(\Lbold_{j})^{\mathrm{T}} )^{\mathrm{T}}$. It can easily be shown that with such a parameterization, $\tilde{\thetavec}_{j}$ follows a multivariate normal distribution with the following specification

$$
\begin{split}
    \tilde{\thetavec}_{j} &\sim \mathcal{N}(\muvec_{j}, \Sigmabold_{j}), \ \text{with} \\
    \Sigmabold_{j} &= \Lbold_{j} \Lbold_{j}^{\mathrm{T}}.
\end{split}
$$

Using this linear transformation $\gvec_{\phivec_{j}}$, we tranform one multivariate normal distribution to another by the change of variable theorem [@Kucukelbir2016, p. 8], here from a multivariate standard normal distribution to a multivarate normal distribution with mean and covariance matrix defined above. $\Lbold_{j}$ is usually chosen to be a lower triangular matrix such that it represents the lower triangular matrix from a Cholesky decompostition. Imposing no constraints on this lower triangular matrix correponds to the non-unique definition of the Choesly factorization. Hence, the diagonal elements of $\mathbf{L}_j$ lack positivity constraints [@Kucukelbir2016]. To use a unique Cholesky factorization, it is necessary to impose constraints on the positivity of the diagonal elements within the lower triangular matrix. The constraints can easily be satisfied by optimizing the diagonal elements in the logarithmic space and subsequently converting them back using the exponential function. In total, we have $d_{j}$ variational parameters for the mean and $\frac{d_{j}(d_{j}+1)}{2}$ variational parameters for the covariance matrix of a parameter in the model. Thus, the number of variational parameters we have to optimize for grows quadratic with the dimension of the parameters. Hence, for regressions models that include smooth effects, one obtains a siceable amount of variational paramters, since a smooth effect usually implies a high dimensional parameter space. In cases involving constrained parameters, while a multivariate normal distribution is utilized in the unconstrained real space of the parameter blocks, the resulting distribution for constrained parameters does not conform to a multivariate normal distribution and instead follows a log-multivariate normal distribution.

Incorporating discrete parameters presents a greater challenge compared to continuous parameters, necessitating the utilization of a distinct transformation function and noise distribution. For an approach to model discrete parameters, consult @Jang2016. To achieve a more flexible variational distribution, advanced techniques encompass the use of non-linear transformation functions by using cutting-edge machine learning approaches such as normalizing flows [@Rezende2015]. The only requirements for $\gvec_{\phivec_{j}}$ are that it must be a bijective and differentiable function. Efficiency considerations furthermore dictate that we should be able to rapidly evaluate the factor within the variational distribution. This implies that we need the ability to calculate the determinant of the Jacobian matrix easily. With the specification of the transformation functions $\gvec$ and $\svec$, we have finally fully determined the variational distribution and thus a complete recipe for a BBVI algorithm.

<!-- Example with the Bayesian linear regression model -->

We will now consider a BBVI setup for the Bayesian linear regression to make the theory more tangible. The variational distribution is again

$$
q(\thetavec | \phivec) = q_{\betavec}(\betavec | \phivec_{\betavec} ) q_{\sigma}(\sigma | \phivec_{\sigma}).
$$

With the linear transformation function established above,we approximate the posteriors of $\betavec$ and $\ln(\sigma)$ in the unconstrained parameter space with the following distributions

$$
\begin{split}
    \betavec &\sim \mathcal{N}(\muvec_{\betavec}, \Sigmabold_{\betavec}) \\
    \ln(\sigma) &\sim \mathcal{N}(\mu_{\sigma}, \varsigma_{\sigma}^{2}),
\end{split}
$$

implying that we used the log-transformation as the function $s^{-1}$ for $\sigma$. The variational parameters in this model are defined as $\phivec = \left( \phivec_{\betavec}^{\mathrm{T}}, \phivec_{\sigma}^{\mathrm{T}} \right)^{\mathrm{T}}$ with $\phivec_{\betavec} = \left(\muvec_{\betavec}^{\mathrm{T}}, \vect( \Lbold_{\betavec} )^{\mathrm{T}} \right)^{\mathrm{T}}$ and $\phivec_{\sigma} = \left( \mu_{\sigma}, \varsigma_{\sigma} \right)^{\mathrm{T}}$. Hence, the maximization problem can be specified as

$$
\hat{\phivec} = \argmax_{\phivec} \text{E}_{p(\epsilonvec_{\betavec})p(\epsilon_{\sigma})} \left[ \ln \left( \frac{p(\yvec|\betavec, \sigma, \X) p(\betavec) p(\sigma)}{q_{\betavec}(\betavec = \gvec_{\phivec_{\betavec}}(\epsilonvec_{\betavec})| \phivec_{\betavec} ) q_{\sigma}(\sigma = s(g_{\phivec_{\sigma}}(\epsilon_{\sigma}))| \phivec_{\sigma})} \right) \right].
$$

Notice how the expectation in the ELBO^[We redefine the ELBO in terms of the variational distribtion, in which we account for the volume compression due to the transformation with $\det(\J_{\gvec^{-1}_{\phivec_{j}}})$ and $\det(\J_{\svec^{-1}})$ . @Kucukelbir2016 leave the variational distribution in the unconstrained space and adjust the joint distribution of the model with $\det(\J_{\gvec_{\phivec_{j}}})$ and $\det(\J_{\svec})$.] is now formulated over the noise distrbutions and not over the variational distribution as in (@eq-elbo-opt). Finally, we can derive the noisy reparameterization gradient $\nabla_{\phivec}\text{ELBO}(\phivec)_{\mathcal{I}}$ by utilizing a random subset of the data, employing Monte Carlo integration and using automatic differentiation on this ELBO. The automatically derived gradient is subsequently employed in Equation (@eq-elbo-sgd) to iteratively refine the parameter estimates, ultimately guiding the optimization process towards a local optimum of the ELBO. This is possible without any support matching constrains imposed by the parameter spaces and minimal effort by the researcher.

## The inference algorithm {#sec-inf-alg}

We now have all the components necessary to define our full BBVI algorithm (Algorithm \ref{algo}). In contrast to the theory outlined in @sec-bbvi, where the variational parameters for a parameter block are defined as $\phivec_{j} = ( \muvec_{j}^{\mathrm{T}}, \vect(\Lbold_{j})^{\mathrm{T}} )^{\mathrm{T}}$ with $\Lbold_{j}$ being the lower triangular matrix from a Cholesky decomposition of the covariance matrix, we modify $\Lbold_{j}$ to be the lower triangular matrix of the precision matrix. This is done due to considerations of linear algebra stability. Optimizing the variational distribution in terms of the lower triangular matrix $\Lbold_{j}$ of the precision matrix is typically more numerically stable than optimizing with respect to $\Lbold_{j}$ of the covariance matrix. Furthermore, we use the unique definition of the Cholesky decomposition for the precision and hence optimize all diagonal elements of $\Lbold_{j}$ in the unconstrained space (log-transformation) and ensure their positivity by using the exponential transformation.

In a first step of the BBVI algorithm, we divide our data into training $\mathcal{D}_{\text{train}}$ and validation $\mathcal{D}_{\text{val}}$ datasets to mitigate the risk of overfitting. Consequently, we monitor the convergence of the ELBO on the validation dataset. Typically, an 80%/20% split (resulting in a training share $w=0.8$) is employed for the training and validation sets, respectively. In preparation, we also randomly permute the data in advance to eliminate any potential dependencies arising from the initial data structure^[This is possible because we are only dealing with independent data structures here.].

Subsequently, we initialize the variational paremeters either with "arbitrary" values or obtain initial values through a pre-train initialization. A common choice for the "arbitrary" intialization is to set the location parameter of a factor to $\muvec_{j} = \zerovec$. The diagonal elements of $\Lbold_{j}$ are usually set to $\diag(\Lbold_{j}) = \onevec$, resulting in the vector $\zerovec$ in the unconstrained space. Our pre-training initialization involves conducting a maximum a posteriori (MAP) optimization for a few iterations, succeeded by a Laplace approximation. This process entails setting the mean of the variational distribution to the mode of the joint log-density of the model and assigning the precision as the negative Hessian at that mode. Such an initialization method yields a starting point remarkably close to the local optimum of the ELBO. This approach has demonstrated significant utility, particularly for distributional regression models that go beyond mere location specifications. For such models using an "arbitrary" initialization proved to be numerically to unstable for estimation.

Afterwards we start the optimization of the ELBO by initializing the optimizer with a learning rate $\alpha$ (usually a small number e.g. 1e-2 or 1e-3) and dynamically adjust the step size during optimization. Adam uses first and second order momentum to dynamically adjust the step size [@Kingma2014]. We then run the optimization for a predetermined number of epochs $E$. Since we use a mini-batch $\mathcal{I}^{k}$ to calculate the gradient (see [Chapter @sec-svinf]) in each iteration $k$, it is common to refer to an epoch $e$ as one iteration loop of the optimization algorithm such that the algorithm has iterated through the entire training dataset. Fixing the mini-batch size $M$ in advance means that one epoch consists of a fixed number of iterations, which is the number of observations in the training set $n_{\text{train}}$ evenly divided by the mini-batch size $M$. Hence, in each iteration during an epoch, we utilize one mini-batch from the created set of mini-batches $\mathcal{B}$, progressing to the next until we have iterated through all mini-batches. At the start of each epoch, we furthermore permute the training data to ensure variation in the mini-batches across epochs. To avoid losing observations, we augment the mini-batch count by including an additional mini-batch if necessary, comprised of any remaining observations. This mini-batch is augmented with resampled indices from the other training data, where the resampling is conducted without replacement. During each iteration of an epoch, we also obtain samples from the noise distribution with the sample size $S$ predetermined in advance. These samples are then transformed to samples from the variational distribution to assess the integral within the ELBO through Monte Carlo integration (see (@eq-repara-grad-mc)). 

Throughout the optimization process, we iteratively refine the configuration of variational parameters towards the local optimum. Additionally, we compute the value of the ELBO using the validation set to monitor convergence. The optimization runs until we either reach the predefined maximum number of epochs or we stop by triggering an early-stopping criterion. Stopping through the early-stopping criterion indicates that we reached some form of plateau in the ELBO of the validation data. We use $|\text{ELBO}(\hat{\phivec}^{t})_{\mathcal{D}_{\text{val}}} - \text{ELBO}(\hat{\phivec}^{t-200})_{\mathcal{D}_{\text{val}}}| < \varepsilon$ as the early stopping criteron, where $\varepsilon$ is an arbitrary small number. The full BBVI algorithm is outlined in Algorithm \ref{algo}.

\begin{algorithm}[H]
    \DontPrintSemicolon
    \scriptsize
    \SetKwInOut{Require}{Require}
    \KwData{$\mathcal{D}_{\text{train}}$; $\mathcal{D}_{\text{val}}$}
    \Require{Learning rate $\alpha$; stopping threshold $\varepsilon$; mini-batch size $M$; share train $w$; num. var. samples $S$; num. epochs: $E$}
    Initialize $\hat{\phivec}^{0}$; set $t = 1$ \;
    \For{$e = 1$  \KwTo $E$}{
        $n_{\text{train}} = |\mathcal{D}_{\text{full}}| * w$ \;
        create the mini-batches, $\mathcal{B} = \{ \dots, \mathcal{I}^{k}, \dots \}, \ k=1, \dots, n_{\text{train}} // M \ (+1)$ \;
        \For{$k=1$ \KwTo $n_{\text{train}} // M \ (+1)$}{
        sample noise, $\epsilonvec^{s}_{j} \sim \mathcal{N}(\zerovec, \I), \ s=1,\dots, S, \ \forall j$ \;
        calculate approx. gradient, $\nabla_{\phivec} \text{ELBO}(\phivec)_{\mathcal{I}^{k}} \Bigr\rvert_{\phivec = \hat{\phivec}^{t-1}}$\;
        update variational parameters, $\hat{\phivec}^{t} = \hat{\phivec}^{t-1} + \rhovec_{t} \odot \nabla_{\phivec} \text{ELBO}(\phivec)_{\mathcal{I}^{k}} \Bigr\rvert_{\phivec = \hat{\phivec}^{t-1}}$ \;
        calculate approx. ELBO, $\text{ELBO}(\hat{\phivec}^{t})_{\mathcal{D}_{\text{val}}}$ \;
        $t = t + 1$ \;
        }
        \eIf{$t > 200$}{
            $\Delta \text{ELBO} = |\text{ELBO}(\hat{\phivec}^{t})_{\mathcal{D}_{\text{val}}} - \text{ELBO}(\hat{\phivec}^{t-200})_{\mathcal{D}_{\text{val}}}|$
        }{$\Delta \text{ELBO} = \infty$
        }
        \If{$\Delta \text{ELBO} < \varepsilon$}{
            \textbf{break}\;
        }
    }
    \KwResult{$\hat{\phivec}$; $\text{ELBO}(\hat{\phivec})_{\mathcal{D}_{\text{val}}}$}
    \caption{BBVI algorithm.}
    \label{algo}
\end{algorithm}

Furthermore, we maintain a record of the maximum ELBO attained, denoted as $\text{ELBO}(\hat{\phivec})_{\mathcal{D}_{\text{val}}}$, along with its corresponding optimal parameter configuration $\hat{\phivec}$. These estimates represent the solution derived for the optimization problem.

## ELBO convergence {#sec-elbo-conv}

Throughout the process of SGD optimization, we track the convergence of the ELBO.
Exemplary ELBO traces, illustrating the impact of varying optimization parameters on a Bayesian linear regression model (see @sec-binf), are visualized in @fig-elbo-trace1 - @fig-elbo-trace4. For this impact study we generated $n_{\text{obs}}=1000$ data points from the following model 

$$
y_{i} | x_{i} \sim \mathcal{N}(1.0 + 2.0x_{i}, 1.0),
$$ 

where $x_{i} \sim \mathcal{U}(0,1)$. Since the ELBO constitutes a non-convex objective, optimization converges towards a local optimum, which is contingent upon its initialization. Moreover, as we work with Monte Carlo integration and mini-batches, we additionally introduce stochasticity into the optimization.

@fig-elbo-trace1 shows that we usually start with some low value of the ELBO, dependent on the initialization. Afterwards, we can observe a steep increase, in which we improve the ELBO fast because we take large steps in the optimization. This fast convergence tapers off before epoch 50 for all traces. It is visible that a more effective initialization leads to a faster convergence. In the following, we are only taking smaller optimization steps because we are already close to the local optimum. The figure underscores that the optimal outcome is reliant on the initialization, as depicted in the embedded figure, even if the differences are relatively minor. Please note that we fixed the seed for all runs to control for the dependence of the optimization on stochasticity. 

@fig-elbo-trace2 shows three different optimization runs with the same initial variational parameter configuration but using distinct seeds. For each run, we observe a distinct ELBO trace, even though we used the same initialization. However, despite the stochasticity, all traces exhibit a rather similar pattern. It is interesting to note that by employing a distinct seed, the runs converge towards distinctly different local optima, emphasizing again the impact of the stochasticity on the optimum.

::: {layout="[[50,-5,50], [50,-5,50]]"}

![ELBO traces for 3 different SGD runs using different initializations and the same seed. We use a batch size of 128, 64 samples from the variational distribution, and a learning rate of 1e-2.](assets/plots/plot2.pdf){fig-scap="ELBO traces for different init. and seeds." #fig-elbo-trace1}

![ELBO traces for 3 different SGD runs using different seeds and the same initialization. Otherwise same configuration as in @fig-elbo-trace1.](assets/plots/plot3.pdf){fig-scap="ELBO traces for different seeds." #fig-elbo-trace2}

![ELBO traces for 3 different SGD run, using different variational sample sizes. We use batch VI with a learning rate of 1e-2 and the same seed as in @fig-elbo-trace1.](assets/plots/plot4.pdf){fig-scap="ELBO traces for different variational sample sizes." #fig-elbo-trace3}

![ELBO traces for 3 different SGD runs using different batch sizes. We use a variational sample size of 64 with a learning rate of 1e-2 and the same seed as in @fig-elbo-trace1.](assets/plots/plot5.pdf){fig-scap="ELBO traces for different batch sizes." #fig-elbo-trace4}

:::

The choice of the variational sample size has a significant impact on the convergence of the ELBO. Using a larger variational sample size significantly reduces the variance of the ELBO and thus its gradient (@fig-elbo-trace3). Furthermore, a stable ELBO plateau is achieved more quickly when utilizing larger samples drawn from the variational distribution. In general, a lower variance allows us to use a larger learning rate, which consequently results in a faster convergence of the ELBO. Again, we use the same seed and all traces converge to a similar local optima. Interestingly, it is evident that employing a single variational sample enables us to achieve a superior optimum when compared to other trial runs. Nevertheless, there is a subtle detail to note here: Due to the pseudo-random number generation in `JAX` ensuring identical pseudo-random number generation for pseudo-random `jax.numpy.ndarrays` becomes challenging due to the dependency on the shape of the array. This implies that we can ensure identical pseudo-random number generation solely when utilizing arrays that possess precisely matching shapes, which is not the case here as we change the variational sample size. Consequently, we cannot completely eliminate the stochastic nature from the results, which could potentially explain the findings observed in this case (likewise for @fig-elbo-trace4).

Employing a larger batch size results in a slight reduction of variance, as illustrated in @fig-elbo-trace4 of the ELBO traces. However, the reduction is rather minor. Be mindful that the variations in batch size result in different iteration counts per epoch for each run. Therefore, we have adapted @fig-elbo-trace4 by showcasing iterations on the x-axis. Using a larger batch size in this scenario does not result in a visible superior local optima of the optimization, all ELBO traces vary around a common level.

For predictive purposes, one can also monitor the log-posterior predictive density. In a first step, we also divide the data set into a training and a validation set. The validation set is then used to asses the average log-posterior predictive density. Hence, we average over all individual log-predictive densities in the validation sample. For some examples in this context, we refer to @Blei2017 and @Kucukelbir2016.